<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xml" href="https://jonnyzzz.com/feed.xslt.xml"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="https://jonnyzzz.com/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://jonnyzzz.com/" rel="alternate" type="text/html" />
  <updated>2026-02-12T19:09:29+00:00</updated>
  <id>/</id>

  
  <title type="html">Eugene Petrenko</title>
  

  
  <subtitle>Founding Engineering Leader | Agentic AI DevTools &amp; Experience</subtitle>
  

  

  
  
  <entry>
    <title type="html">When Your IntelliJ Plugin Works in Tests but Fails in Production</title>
    <link href="https://jonnyzzz.com/blog/2026/02/12/jvm-classloading-intellij/" rel="alternate" type="text/html" title="When Your IntelliJ Plugin Works in Tests but Fails in Production" />
    <published>2026-02-12T00:00:00+00:00</published>
    <updated>2026-02-12T00:00:00+00:00</updated>
    <id>/blog/2026/02/12/jvm-classloading-intellij</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/02/12/jvm-classloading-intellij/">&lt;p&gt;If your IntelliJ plugin works in tests but fails in production with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkageError&lt;/code&gt;,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassCastException&lt;/code&gt;, or plugin conflicts, you are likely hitting a classloader boundary problem.
Let’s walk through what actually happens and how to stay safe.&lt;/p&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#foundation-how-jvm-classloading-works&quot;&gt;Foundation: How JVM Classloading Works&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#basic-classloaders&quot;&gt;Basic Classloaders&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#duplicate-dependencies&quot;&gt;Duplicate Dependencies&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#how-it-works&quot;&gt;How It Works&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#intellij-plugin-classloading&quot;&gt;IntelliJ Plugin Classloading&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#plugin-classloader-architecture&quot;&gt;Plugin Classloader Architecture&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kotlin-libraries-in-plugins&quot;&gt;Kotlin Libraries in Plugins&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#why-kotlin-libraries-are-special&quot;&gt;Why Kotlin Libraries Are Special&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#build-time-verification&quot;&gt;Build-Time Verification&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#common-isolation-patterns&quot;&gt;Common Isolation Patterns&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#shadow-jar-and-relocation&quot;&gt;Shadow JAR and Relocation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#independent-classloader-hierarchies&quot;&gt;Independent Classloader Hierarchies&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#testing-and-classloaders&quot;&gt;Testing and Classloaders&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#why-test-runtime-differs-from-production&quot;&gt;Why Test Runtime Differs from Production&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#test-fixtures-and-dependencies&quot;&gt;Test Fixtures and Dependencies&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#platform-upgrades-and-breaking-changes&quot;&gt;Platform Upgrades and Breaking Changes&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#resource-bundle-loading&quot;&gt;Resource Bundle Loading&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#common-test-failures&quot;&gt;Common Test Failures&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#debugging-test-classloaders&quot;&gt;Debugging Test Classloaders&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#best-practices-for-plugin-tests&quot;&gt;Best Practices for Plugin Tests&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#advanced-topics&quot;&gt;Advanced Topics&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#embedding-compilers&quot;&gt;Embedding Compilers&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#serviceloader-and-classloader-context&quot;&gt;ServiceLoader and Classloader Context&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#debugging-classloaders-in-production&quot;&gt;Debugging Classloaders in Production&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#start-with-verbose-class-logging&quot;&gt;Start with Verbose Class Logging&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#inspect-class-origin-at-runtime&quot;&gt;Inspect Class Origin at Runtime&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#find-duplicate-jars&quot;&gt;Find Duplicate JARs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#process-inspection-tools&quot;&gt;Process Inspection Tools&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#intellij-debugger-inspector&quot;&gt;IntelliJ Debugger Inspector&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#detect-duplicates-early&quot;&gt;Detect Duplicates Early&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#common-error-patterns&quot;&gt;Common Error Patterns&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#log-classloader-hierarchies&quot;&gt;Log Classloader Hierarchies&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#practical-workflow&quot;&gt;Practical Workflow&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;foundation-how-jvm-classloading-works&quot;&gt;Foundation: How JVM Classloading Works&lt;/h2&gt;

&lt;h3 id=&quot;basic-classloaders&quot;&gt;Basic Classloaders&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;For the JVM the key of each class is ClassLoader instance + class full name&lt;/li&gt;
  &lt;li&gt;At the bytecode level, the key is only the class fully qualified name (FQN)&lt;/li&gt;
  &lt;li&gt;Classloaders are connected in the graph, and each class calls its own classloader to load classes.&lt;/li&gt;
  &lt;li&gt;Classloader implements the strategy to look for a class, in it’s classpath, or in other classloaders.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The problems start when classes resolve it’s FQN to different Class instances, and to different classloaders. 
Usually you see that as LinkageError or similar exceptions.&lt;/p&gt;

&lt;p&gt;The base class for all classloaders is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassLoader&lt;/code&gt; class. In JDK 8 and in many plugin/container
implementations, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;URLClassLoader&lt;/code&gt; is a common concrete class, but this is not universal on newer JDKs.
You need to create your own classloader if you want to change something.&lt;/p&gt;

&lt;p&gt;With this baseline, let’s talk about duplicate dependencies.&lt;/p&gt;

&lt;h3 id=&quot;duplicate-dependencies&quot;&gt;Duplicate Dependencies&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Rule Number One:&lt;/strong&gt; Never ship duplicate runtime libraries across classloader boundaries
unless isolation is explicit and tested.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Start with dependency hygiene. Make sure your build system resolves the classpath correctly. I recommend to include
the strong assertions on which JAR files you are including into your application. For example, it can be that
you depend on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-stdlib&lt;/code&gt; 2.1.20, and your transitive dependencies bring &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-reflect&lt;/code&gt; 1.9.24.
It will unlikely to work.&lt;/p&gt;

&lt;p&gt;Ok, now assume you cannot change that, and you have two JARs with the same-named classes. How would you do?
It happens when you want to integration into an existing big application, for example IntelliJ-based IDE.
Check the &lt;strong&gt;Rule Number One&lt;/strong&gt; first.&lt;/p&gt;

&lt;p&gt;So how can you make your classes load a class &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;com.jonnyzzz.AI&lt;/code&gt; of your own jar, while the rest of the application
load the same-named class from their own jar?&lt;/p&gt;

&lt;p&gt;You need to implement the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassLoader&lt;/code&gt; different way. Usually, inherit from the URLClassLoader and change the
strategy in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;findClass&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;findResource&lt;/code&gt; methods. You need to change the logic:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the default logic: classloader looks for the class in the parent classloader first&lt;/li&gt;
  &lt;li&gt;the changed logic: your classloader looks in its own classpath first and only next calls the parent.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The standard &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassLoader&lt;/code&gt; API assumes a single parent, but real-world implementations may differ.
IntelliJ’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PluginClassLoader&lt;/code&gt;, for example, maintains multiple parent references to implement the plugin
dependency graph. Other application containers and frameworks may have their own classloader hierarchies and
delegation strategies beyond the simple parent-first chain.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; In practice, many application containers use non-tree-based classloader hierarchies. IntelliJ
plugin classloaders have multiple parents (following the plugin dependency graph), not a single parent chain.
The parent traversal pattern shown here is a simplified model. Real-world hierarchies require more complex
delegation logic.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is easy and complicated. First of all, once you did that, you cannot use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;com.jonnyzzz.AI&lt;/code&gt; class from that
parent application, because you have another &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Class&lt;/code&gt; instance, and there are two different classes with the same
name.&lt;/p&gt;

&lt;p&gt;This is where the problems start, and this is why we have &lt;strong&gt;Rule Number One&lt;/strong&gt;. And the same applies to the resources
resolution by ClassLoader.&lt;/p&gt;

&lt;h3 id=&quot;how-it-works&quot;&gt;How It Works&lt;/h3&gt;

&lt;p&gt;Only very carefully. You can only use the classes, which you are not overriding.&lt;/p&gt;

&lt;p&gt;For example, you can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PsiElement&lt;/code&gt; from the IntelliJ, and call your own &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ktor&lt;/code&gt; server.&lt;/p&gt;

&lt;h2 id=&quot;intellij-plugin-classloading&quot;&gt;IntelliJ Plugin Classloading&lt;/h2&gt;

&lt;h3 id=&quot;plugin-classloader-architecture&quot;&gt;Plugin Classloader Architecture&lt;/h3&gt;

&lt;p&gt;Applications like IntelliJ provides the classloader infrastructure and load your plugin code in their
dedicated classloader. Such classloader is designed to look at your plugin’s lib folder first,
and look at the other classloaders next.&lt;/p&gt;

&lt;p&gt;Each plugin in IntelliJ is loaded with its own classloader. Classloaders are organized in the Graph,
replicating plugin dependencies, declared in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;plugin.xml&lt;/code&gt; files. Tricky?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; IntelliJ’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PluginClassLoader&lt;/code&gt; does not follow the simple single-parent tree model. Each plugin
classloader has multiple parents corresponding to its declared dependencies. When you call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getParent()&lt;/code&gt;, you
only see one parent, but the actual delegation logic queries all dependency classloaders. This non-tree hierarchy
means standard parent-chain traversal code will not capture the full classloader topology.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;kotlin-libraries-in-plugins&quot;&gt;Kotlin Libraries in Plugins&lt;/h2&gt;

&lt;h3 id=&quot;why-kotlin-libraries-are-special&quot;&gt;Why Kotlin Libraries Are Special&lt;/h3&gt;

&lt;p&gt;Before we move to classloader testing and deep isolation, there is one Kotlin-specific caveat.&lt;/p&gt;

&lt;p&gt;Kotlin libraries are yet another story. Kotlin/JVM gives strong backward binary compatibility for
stable compiler output, but forward compatibility is not guaranteed, and library compatibility is
library-specific. Coroutines, Serialization, and other libraries can be tricky. I recommend carefully
reading the &lt;a href=&quot;https://kotlinlang.org&quot;&gt;kotlinlang.org&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;In IntelliJ, prefer Kotlin libraries bundled with your target platform. In most cases, do not package
your own &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-stdlib&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-reflect&lt;/code&gt;, or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlinx-coroutines-core&lt;/code&gt; unless your compatibility
matrix explicitly requires it. Write an assert in your build system to avoid accidental duplicates.&lt;/p&gt;

&lt;h3 id=&quot;build-time-verification&quot;&gt;Build-Time Verification&lt;/h3&gt;

&lt;p&gt;Here is how you can verify your plugin does not bundle forbidden libraries. Add a Gradle task that
inspects the built plugin ZIP and fails the build if Kotlin runtime libraries are found. This catches
dependency misconfigurations early, before they cause &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassCastException&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkageError&lt;/code&gt; in production.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;verifyPluginLibs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;registering&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;dependsOn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buildPlugin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;doLast&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;zipFile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buildPlugin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;singleFile&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;libs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ZipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zip&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;entries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;asSequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/lib/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;endsWith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;.jar&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;substringAfterLast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;forbidden&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;listOf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kotlin-stdlib&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;kotlin-reflect&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;kotlinx-coroutines-core&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;violations&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jar&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forbidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;any&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;startsWith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;violations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;Forbidden libraries bundled: ${violations.joinToString()}&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Why it’s so important? Here is the example:
Take a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;suspend fun &amp;lt;T&amp;gt; test(value: T): T&lt;/code&gt;, it is compiled to a JVM signature like
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Object test(T value, Continuation&amp;lt;? super T&amp;gt; c)&lt;/code&gt;.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Continuation&lt;/code&gt; interface comes from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-stdlib&lt;/code&gt; (package &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin.coroutines&lt;/code&gt;). And in order to make it work,
you need to have the same class loaded across classloader boundaries. That is vital when you call
shared &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;suspend&lt;/code&gt; APIs across those boundaries.&lt;/p&gt;

&lt;p&gt;The same classloading principles explain most test/runtime mismatches too.&lt;/p&gt;

&lt;h2 id=&quot;common-isolation-patterns&quot;&gt;Common Isolation Patterns&lt;/h2&gt;

&lt;h3 id=&quot;shadow-jar-and-relocation&quot;&gt;Shadow JAR and Relocation&lt;/h3&gt;

&lt;p&gt;If dependency alignment is not possible, the next mitigation is relocation.&lt;/p&gt;

&lt;p&gt;Shadow Jar is another technique. On one side, it helps to create a huge monolithic JAR, which you can &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java -jar&lt;/code&gt;
to start.&lt;/p&gt;

&lt;p&gt;The most powerful feature is the classes’ relocation. Basically, it takes the bytecode, and changes the FQN’s
of the classes and information in other places to turn your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;com.jonnyzzz.AI&lt;/code&gt; class into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relocate.package.com.jonnyzzz.AI&lt;/code&gt;
class.&lt;/p&gt;

&lt;p&gt;Here is the place where problems start – your code may use metadata, reflection, and other tricks which the
relocation logic may not see or find. Like Kotlin’s metadata for example. This is where the &lt;strong&gt;Rule Number One&lt;/strong&gt; is necessary.&lt;/p&gt;

&lt;h3 id=&quot;independent-classloader-hierarchies&quot;&gt;Independent Classloader Hierarchies&lt;/h3&gt;

&lt;p&gt;When relocation is still not enough, the next step is dedicated classloader hierarchies.&lt;/p&gt;

&lt;p&gt;The whole JVM starts from the Bootstrap classloader (written in native code), which loads the
Java Standard Library. Next comes the Platform classloader, and then the System/Application
classloader for your application classes. On practice, you can add more classes to that classpath, be very careful.&lt;/p&gt;

&lt;p&gt;Nevertheless, we can build the following structure&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph TD
    BootstrapCL[&quot;Bootstrap ClassLoader&amp;lt;br/&amp;gt;(Java Standard Library)&quot;]

    AppCL[&quot;Application ClassLoader&amp;lt;br/&amp;gt;(Your Application)&quot;]
    CustomCL[&quot;Custom ClassLoader&amp;lt;br/&amp;gt;(parent = null)&amp;lt;br/&amp;gt;(Isolated Application)&quot;]

    BootstrapCL --&amp;gt; AppCL
    BootstrapCL --&amp;gt; CustomCL

    style BootstrapCL fill:#e1f5ff
    style AppCL fill:#fff4e6
    style CustomCL fill:#f3e5f5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can build your own classloader hierarchy, for example you can start from the Bootstrap classloader.
For that, you load classes to your classloader in the following way &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new URLClassLoader(classpath, null)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You pass &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt; as the parent classloader to your URL classloader. This delegates to the Bootstrap classloader,
avoiding any interaction with the Application classpath, but the cost is – you can only use Java Standard
Library classes as the common ground. And thus you will do reflection.&lt;/p&gt;

&lt;p&gt;I do recommend that approach, if you need to load a complex application, which may do much tricky stuff inside.&lt;/p&gt;

&lt;p&gt;You should understand, this is a good, but not 100% isolation. Both applications can still conflict for the same
common resources like ForkJoinPool, or System Properties.&lt;/p&gt;

&lt;p&gt;Sometimes, it’s possible to add your API JAR to the beginning. Usually it’s not possible in the complex applications.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph TD
    BootstrapCL[&quot;Bootstrap ClassLoader&amp;lt;br/&amp;gt;(Java Standard Library)&quot;]

    APICL[&quot;API ClassLoader&amp;lt;br/&amp;gt;(Shared API JAR)&quot;]

    AppA[&quot;Application A ClassLoader&quot;]
    AppB[&quot;Application B ClassLoader&quot;]

    BootstrapCL --&amp;gt; APICL
    APICL --&amp;gt; AppA
    APICL --&amp;gt; AppB

    style BootstrapCL fill:#e1f5ff
    style APICL fill:#e8f5e9
    style AppA fill:#fff4e6
    style AppB fill:#f3e5f5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, that is not an easy business, just consider what you do with Logging and all 5+ logging libraries you have.
Logging libraries usually have assertions to help you implement that correctly. This is vital tool.&lt;/p&gt;

&lt;p&gt;This is another place where &lt;strong&gt;Rule Number One&lt;/strong&gt; applies.&lt;/p&gt;

&lt;h2 id=&quot;testing-and-classloaders&quot;&gt;Testing and Classloaders&lt;/h2&gt;

&lt;p&gt;Here is a pattern I keep seeing: plugin works in the IDE, tests fail with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resource not found&lt;/code&gt; or
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassNotFoundException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In most cases this is not random. Test runtime classloading is different from production runtime classloading.&lt;/p&gt;

&lt;h3 id=&quot;why-test-runtime-differs-from-production&quot;&gt;Why Test Runtime Differs from Production&lt;/h3&gt;

&lt;p&gt;In production, your plugin code is loaded by IntelliJ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PluginClassLoader&lt;/code&gt;. Plugin classloaders are isolated and linked
as a dependency graph based on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;plugin.xml&lt;/code&gt; dependencies.&lt;/p&gt;

&lt;p&gt;In tests, you run a dedicated test JVM. The IntelliJ Platform test framework is initialized inside that process, with
its own classpath and test framework artifacts. On modern platform targets, test tasks also run with
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-Djava.system.class.loader=com.intellij.util.lang.PathClassLoader&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;So class and resource resolution surface is different by design:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;production: real IDE distribution + real plugin graph&lt;/li&gt;
  &lt;li&gt;tests: test runtime classpath + selected test framework modules/plugins&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If runtime works and tests fail, the first suspect is usually test runtime composition.&lt;/p&gt;

&lt;h3 id=&quot;test-fixtures-and-dependencies&quot;&gt;Test Fixtures and Dependencies&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BasePlatformTestCase&lt;/code&gt; and related fixture-based tests bootstrap IntelliJ test application and project infrastructure
in-process. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LightJavaCodeInsightFixtureTestCase&lt;/code&gt; builds on light fixtures and Java-specific test setup.&lt;/p&gt;

&lt;p&gt;The important operational detail is dependency provisioning:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;test framework dependencies are explicit&lt;/li&gt;
  &lt;li&gt;Java-specific tests require Java test framework/plugin artifacts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With IntelliJ Platform Gradle plugin 2.x, this is expressed as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;testFramework(...)&lt;/code&gt; dependencies, for example:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;intellijPlatform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;testFramework&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TestFrameworkType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Platform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;testFramework&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TestFrameworkType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Plugin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Java&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Without Java test framework dependencies, Java classes/resources (including Java bundle resources) may be absent in
unit tests even if runtime IDE behavior looks fine.&lt;/p&gt;

&lt;h3 id=&quot;platform-upgrades-and-breaking-changes&quot;&gt;Platform Upgrades and Breaking Changes&lt;/h3&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024.2&lt;/code&gt; platform line came with module layout changes significant enough that JetBrains recommends migrating to
IntelliJ Platform Gradle plugin &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2.x&lt;/code&gt; when targeting &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024.2+&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;That upgrade often changes what lands on your test runtime classpath:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;some dependencies that were previously available implicitly are no longer there&lt;/li&gt;
  &lt;li&gt;tests become more sensitive to explicitly declared platform/plugin test dependencies&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So migrating from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024.1.7&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024.2.x&lt;/code&gt; can expose hidden assumptions in tests, especially around Java-related PSI,
resources, and plugin dependency wiring.&lt;/p&gt;

&lt;h3 id=&quot;resource-bundle-loading&quot;&gt;Resource Bundle Loading&lt;/h3&gt;

&lt;p&gt;IntelliJ message bundles are classpath resources (for example &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;messages/MyBundle.properties&lt;/code&gt;) resolved by bundle name.&lt;/p&gt;

&lt;p&gt;Two practical gotchas matter a lot in tests:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bundle base names are global on classpath, duplicate names across artifacts can resolve by loading order&lt;/li&gt;
  &lt;li&gt;test runtime packaging and order can differ from production plugin packaging&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This means bundle lookups can succeed in production but fail in tests (or resolve to the wrong bundle) if classpath
composition differs.&lt;/p&gt;

&lt;p&gt;If you see errors like:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ERROR: &apos;filetype.java.module.display.name&apos; is not found
(baseBundleName=messages.JavaPsiBundle, ...)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Validate that Java plugin/test framework dependencies are present for tests, and that no packaging or relocation
changed resource paths.&lt;/p&gt;

&lt;h3 id=&quot;common-test-failures&quot;&gt;Common Test Failures&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resource not found&lt;/code&gt;: usually missing test framework plugin dependency or wrong bundle path/name&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassNotFoundException&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NoClassDefFoundError&lt;/code&gt;: dependency missing from test runtime, often hidden by runtime IDE&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceConfigurationError&lt;/code&gt;: service interface/impl loaded via incompatible classloaders&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;debugging-test-classloaders&quot;&gt;Debugging Test Classloaders&lt;/h3&gt;

&lt;p&gt;Use a short diagnostic helper inside failing tests:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dumpClassloading&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resourcePath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Class: ${anchor.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ClassLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classLoader&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;  loader -&amp;gt; $cl&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Resource &apos;$resourcePath&apos; -&amp;gt; ${anchor.classLoader?.getResource(resourcePath)}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And enable class loading logs for the test JVM:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;jvmArgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-Xlog:class+load=info&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For every failing symbol/resource, answer two questions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Which classloader loaded it?&lt;/li&gt;
  &lt;li&gt;From which JAR/resource URL did it come?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That usually localizes the problem quickly.&lt;/p&gt;

&lt;h3 id=&quot;best-practices-for-plugin-tests&quot;&gt;Best Practices for Plugin Tests&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Keep platform target and IntelliJ Platform Gradle plugin aligned (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024.2+&lt;/code&gt; =&amp;gt; plugin &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2.x&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;Declare plugin dependencies explicitly in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;plugin.xml&lt;/code&gt; and mirror them in test framework dependencies.&lt;/li&gt;
  &lt;li&gt;Add Java test framework/plugin dependencies for Java PSI tests (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TestFrameworkType.Plugin.Java&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;Use unique bundle names and stable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;messages/...&lt;/code&gt; paths; avoid collisions.&lt;/li&gt;
  &lt;li&gt;Avoid relocating/shading IntelliJ and Kotlin platform classes/resources into plugin test runtime.&lt;/li&gt;
  &lt;li&gt;Add at least one CI lane that runs tests on both the previous and target platform baselines.&lt;/li&gt;
  &lt;li&gt;When deep isolation is required (compiler/complex toolchains), prefer process isolation over classloader tricks
(see &lt;a href=&quot;#embedding-compilers&quot;&gt;Embedding Compilers&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advanced-topics&quot;&gt;Advanced Topics&lt;/h2&gt;

&lt;h3 id=&quot;embedding-compilers&quot;&gt;Embedding Compilers&lt;/h3&gt;

&lt;p&gt;After the classloading post, I got a very practical question:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Can I just add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-compiler-embeddable&lt;/code&gt; to my IntelliJ plugin and call it directly?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can. But this is where plugin classloading gets expensive very quickly.&lt;/p&gt;

&lt;p&gt;In IntelliJ plugins, the biggest risk is runtime topology:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IDE Kotlin + plugin Kotlin + compiler Kotlin classes in one JVM process&lt;/li&gt;
  &lt;li&gt;different version expectations for the same APIs&lt;/li&gt;
  &lt;li&gt;many more places where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkageError&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NoSuchMethodError&lt;/code&gt; appear&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For that reason, I usually recommend process isolation first.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;&lt;a href=&quot;https://mcp-steroid.jonnyzzz.com&quot;&gt;MCP Steroid&lt;/a&gt;&lt;/strong&gt; we call the Kotlin compiler in a separate process and
exchange data through explicit request/result payloads. It is slower than a pure in-process call, but it keeps
classloader boundaries stable and failure domain small.&lt;/p&gt;

&lt;p&gt;If compile frequency grows, you can move to a daemon process later without changing the protocol.&lt;/p&gt;

&lt;h3 id=&quot;alternative-isolated-classloader-for-compiler&quot;&gt;Alternative: Isolated ClassLoader for Compiler&lt;/h3&gt;

&lt;p&gt;If process isolation is too heavy for your use case, you can embed &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kotlin-compiler-embeddable&lt;/code&gt; in a fully
isolated classloader using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;URLClassLoader(classpath, parent = null)&lt;/code&gt; pattern.&lt;/p&gt;

&lt;p&gt;This delegates only to the Bootstrap ClassLoader (Java Standard Library), avoiding all conflicts with IDE’s
Kotlin runtime and your plugin’s dependencies:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;compilerJars&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;listOf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* kotlin-compiler-embeddable.jar and its dependencies */&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toURI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toURL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toTypedArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;isolatedLoader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;URLClassLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compilerJars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// parent = null&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;compilerClass&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isolatedLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;loadClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.jetbrains.kotlin.cli.jvm.K2JVMCompiler&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;compiler&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compilerClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getDeclaredConstructor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;newInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Call compiler methods via reflection&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Communication limited to Java Standard Library types (String, arrays, primitives)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Trade-offs:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;✓ Full isolation from IDE and plugin Kotlin versions&lt;/li&gt;
  &lt;li&gt;✓ No &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkageError&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassCastException&lt;/code&gt; from version conflicts&lt;/li&gt;
  &lt;li&gt;✗ Reflection-only API (no direct method calls)&lt;/li&gt;
  &lt;li&gt;✗ Communication limited to JDK types (String, byte[], primitives)&lt;/li&gt;
  &lt;li&gt;✗ More verbose than direct calls&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This pattern works for any complex library with version conflicts. But remember: if you need more than
reflection + JDK types for communication, process isolation is cleaner.&lt;/p&gt;

&lt;h3 id=&quot;serviceloader-and-classloader-context&quot;&gt;ServiceLoader and Classloader Context&lt;/h3&gt;

&lt;p&gt;Another place where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassLoader + FQN&lt;/code&gt; hurts in plugin code is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The naive call looks innocent:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyExtension&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extensions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyExtension&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In plugin architectures this is often wrong. That overload uses
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Thread.currentThread().getContextClassLoader()&lt;/code&gt; (TCCL), not
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MyExtension.class.getClassLoader()&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader&lt;/code&gt; only sees providers visible from the classloader you pass to it
(or from TCCL when loader is not specified).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader.load(service, loader)&lt;/code&gt; at host/plugin boundaries:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;ClassLoader&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pluginLoader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// plugin classloader&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyExtension&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyExtension&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pluginLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader&lt;/code&gt; only searches the classloader you pass to it. In non-tree-based hierarchies
(IntelliJ plugins with multiple dependencies, OSGi bundles), providers may be visible through one parent but
not another. If discovery fails, check that the provider’s JAR is reachable from the exact classloader you
pass to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader.load()&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;why-this-fails-in-real-plugins&quot;&gt;Why this fails in real plugins&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader&lt;/code&gt; loads provider class names from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;META-INF/services/&amp;lt;service-fqn&amp;gt;&lt;/code&gt;, then instantiates providers
with the same classloader, and finally casts providers to the service type class object you pass in.&lt;/p&gt;

&lt;p&gt;If your provider implements &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MyExtension&lt;/code&gt; loaded from a different classloader, you get:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceConfigurationError: ... not a subtype&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;tccl-swap-for-nested-discovery&quot;&gt;TCCL swap for nested discovery&lt;/h4&gt;

&lt;p&gt;Even when you pass explicit classloaders in your own code, third-party initialization code often calls
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader.load(service)&lt;/code&gt; internally. That code depends on TCCL.&lt;/p&gt;

&lt;p&gt;Use a temporary context swap:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;withContextClassLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ClassLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;thread&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;prev&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contextClassLoader&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contextClassLoader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contextClassLoader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prev&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Practical usage:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;services&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;withContextClassLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pluginLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyExtension&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pluginLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;serviceloader-checklist-for-plugin-systems&quot;&gt;ServiceLoader checklist for plugin systems&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Keep SPI interfaces in a shared parent loader, not duplicated in each plugin.&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ServiceLoader.load(service, explicitLoader)&lt;/code&gt; in boundary code.&lt;/li&gt;
  &lt;li&gt;Verify &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;META-INF/services/...&lt;/code&gt; survives shading and packaging.&lt;/li&gt;
  &lt;li&gt;Validate providers at plugin startup and fail fast with clear logs.&lt;/li&gt;
  &lt;li&gt;Release provider references on plugin unload to avoid classloader leaks.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;debugging-classloaders-in-production&quot;&gt;Debugging Classloaders in Production&lt;/h2&gt;

&lt;p&gt;Theory helps, but incidents usually start with one ugly stacktrace in CI or in plugin tests.&lt;/p&gt;

&lt;p&gt;When we debug classloading conflicts, we always collect three facts first:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;class FQN&lt;/li&gt;
  &lt;li&gt;classloader identity (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassLoader&lt;/code&gt; class + instance id)&lt;/li&gt;
  &lt;li&gt;bytecode source (which JAR/directory)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Everything below is about getting these facts quickly and reproducibly.&lt;/p&gt;

&lt;h3 id=&quot;start-with-verbose-class-logging&quot;&gt;Start with Verbose Class Logging&lt;/h3&gt;

&lt;p&gt;The fastest first move is to run the failing scenario with class loading logs enabled.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java &lt;span class=&quot;nt&quot;&gt;-verbose&lt;/span&gt;:class &lt;span class=&quot;nt&quot;&gt;-jar&lt;/span&gt; app.jar 2&amp;gt;&amp;amp;1 | &lt;span class=&quot;nb&quot;&gt;tee&lt;/span&gt; /tmp/classload.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For tests, forcing it via environment usually works better than changing build scripts:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_TOOL_OPTIONS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-verbose:class&quot;&lt;/span&gt;
./gradlew &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tests&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;*Formatting*&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then filter to suspicious classes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rg &lt;span class=&quot;s1&quot;&gt;&apos;JavaPsiBundle|kotlin/coroutines/Continuation|com/example/YourType&apos;&lt;/span&gt; /tmp/classload.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On newer JDKs, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-Xlog:class+load=info&lt;/code&gt; gives cleaner output. I still start with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-verbose:class&lt;/code&gt; because it is
portable and works everywhere.&lt;/p&gt;

&lt;h3 id=&quot;inspect-class-origin-at-runtime&quot;&gt;Inspect Class Origin at Runtime&lt;/h3&gt;

&lt;p&gt;A stacktrace alone often hides the real issue: same FQN, different loader instance.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;logClassOrigin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classLoader&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;loaderId&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;bootstrap&quot;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;${loader.javaClass.name}@${System.identityHashCode(loader).toString(16)}&quot;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;protectionDomain&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;codeSource&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toExternalForm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;?:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;unknown&amp;gt;&quot;&lt;/span&gt;

  &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${type.name} -&amp;gt; loader=$loaderId, source=$source&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;logContextLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contextClassLoader&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;thread contextClassLoader = ${cl ?: &quot;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bootstrap&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Use this on both sides of the failing call, not only where the exception is thrown.&lt;/p&gt;

&lt;h3 id=&quot;find-duplicate-jars&quot;&gt;Find Duplicate JARs&lt;/h3&gt;

&lt;p&gt;If you suspect duplicates, search runtime JARs directly.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;kotlin/coroutines/Continuation.class&apos;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;j &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;lib/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.jar&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;jar tf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$j&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; | rg &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$target&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;$&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$j&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For arbitrary classpaths:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;com/example/MyService.class&apos;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;tr&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;:&apos;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;\n&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$CLASSPATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; | &lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; e&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
  if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.jar &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;jar tf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; | rg &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$target&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;$&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$target&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$e&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; (directory)&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;fi
done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If this prints more than one location, you already have a strong signal for conflict.&lt;/p&gt;

&lt;h3 id=&quot;process-inspection-tools&quot;&gt;Process Inspection Tools&lt;/h3&gt;

&lt;p&gt;Use these tools when you need to inspect a running IDE, Gradle daemon, or long-lived service.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1) find the right JVM process&lt;/span&gt;
jps &lt;span class=&quot;nt&quot;&gt;-lv&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 2) inspect startup args and classpath&lt;/span&gt;
jcmd &amp;lt;pid&amp;gt; VM.command_line
jcmd &amp;lt;pid&amp;gt; VM.system_properties | rg &lt;span class=&quot;s1&quot;&gt;&apos;^java.class.path=&apos;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 3) inspect classloader data (JDK-dependent command set)&lt;/span&gt;
jcmd &amp;lt;pid&amp;gt; &lt;span class=&quot;nb&quot;&gt;help&lt;/span&gt; | rg &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; class
jcmd &amp;lt;pid&amp;gt; VM.classloaders

&lt;span class=&quot;c&quot;&gt;# 4) class histogram and loader stats&lt;/span&gt;
jcmd &amp;lt;pid&amp;gt; GC.class_histogram | &lt;span class=&quot;nb&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 40
jmap &lt;span class=&quot;nt&quot;&gt;-clstats&lt;/span&gt; &amp;lt;pid&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jcmd &amp;lt;pid&amp;gt; help&lt;/code&gt; is useful because available commands vary by JDK version.&lt;/p&gt;

&lt;h3 id=&quot;intellij-debugger-inspector&quot;&gt;IntelliJ Debugger Inspector&lt;/h3&gt;

&lt;p&gt;In IntelliJ, we usually do not need extra plugins to debug classloading.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Run/attach debugger to the failing process (test JVM, IDE instance, or plugin sandbox).&lt;/li&gt;
  &lt;li&gt;Put a breakpoint right before the failing cast/linkage point.&lt;/li&gt;
  &lt;li&gt;Evaluate these expressions:
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;obj.getClass().getClassLoader()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;obj.getClass().getProtectionDomain().getCodeSource().getLocation()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Thread.currentThread().getContextClassLoader()&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Compare the same expressions in a working scenario.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For IntelliJ plugin debugging, you will often see &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PluginClassLoader&lt;/code&gt; instances. The important part is not the name,
but whether two objects with the same class name come from different loader instances.&lt;/p&gt;

&lt;h3 id=&quot;detect-duplicates-early&quot;&gt;Detect Duplicates Early&lt;/h3&gt;

&lt;p&gt;Do this check before deep debugging. It saves hours.&lt;/p&gt;

&lt;p&gt;Gradle:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./gradlew :plugin:dependencyInsight &lt;span class=&quot;nt&quot;&gt;--configuration&lt;/span&gt; runtimeClasspath &lt;span class=&quot;nt&quot;&gt;--dependency&lt;/span&gt; kotlin-stdlib
./gradlew :plugin:dependencyInsight &lt;span class=&quot;nt&quot;&gt;--configuration&lt;/span&gt; runtimeClasspath &lt;span class=&quot;nt&quot;&gt;--dependency&lt;/span&gt; kotlin-reflect
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Maven:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-DincludeScope&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;runtime dependency:tree
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Manual check for one class:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;org/slf4j/Logger.class&apos;&lt;/span&gt;
find &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-name&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;*.jar&apos;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-print0&lt;/span&gt; | &lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;IFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&apos;&lt;/span&gt; j&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;jar tf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$j&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; | rg &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$target&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;$&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$j&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;common-error-patterns&quot;&gt;Common Error Patterns&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkageError&lt;/code&gt;
Typical message: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loader constraint violation&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duplicate class definition&lt;/code&gt;
Usually means: binary-incompatible or duplicate definitions across loaders
First check: compare class source JAR and loader identity on both call sides&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassCastException&lt;/code&gt;
Typical message: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X cannot be cast to X&lt;/code&gt;
Usually means: same FQN loaded by different classloaders
First check: print &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getClassLoader()&lt;/code&gt; for both objects/classes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NoClassDefFoundError&lt;/code&gt;
Typical message: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Could not initialize class ...&lt;/code&gt; or missing class at runtime
Usually means: missing runtime dependency, wrong loader visibility, or init failure
First check: inspect &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Caused by&lt;/code&gt;, then verify classpath and loader hierarchy&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X cannot be cast to X&lt;/code&gt; message is the classic classloader smell.&lt;/p&gt;

&lt;h3 id=&quot;log-classloader-hierarchies&quot;&gt;Log Classloader Hierarchies&lt;/h3&gt;

&lt;p&gt;This helper is simple and very effective in incident reports:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dumpLoaderChain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ClassLoader&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ClassLoader&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;  &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;bootstrap&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;indent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getClass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;@&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toHexString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;identityHashCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;URLClassLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;URLClassLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getURLs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;  - &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getParent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; This code assumes a single-parent tree hierarchy and only follows &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getParent()&lt;/code&gt;. Real-world
classloaders (IntelliJ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PluginClassLoader&lt;/code&gt;, OSGi, application servers) often have multiple parents or custom
delegation strategies. Use this helper for initial debugging, but be aware it may not show the full classloader
topology in complex plugin architectures.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Call it for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Thread.currentThread().getContextClassLoader()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YourApi.class.getClassLoader()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YourImpl.class.getClassLoader()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This usually makes hidden hierarchy issues obvious.&lt;/p&gt;

&lt;h3 id=&quot;practical-workflow&quot;&gt;Practical Workflow&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Reproduce once with fixed inputs and fixed JVM args.&lt;/li&gt;
  &lt;li&gt;Enable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-verbose:class&lt;/code&gt; and capture logs.&lt;/li&gt;
  &lt;li&gt;Pick one failing class and print loader + code source at runtime.&lt;/li&gt;
  &lt;li&gt;Dump classloader chain for context loader and key classes.&lt;/li&gt;
  &lt;li&gt;Run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jps&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jcmd&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jmap&lt;/code&gt; against the failing process.&lt;/li&gt;
  &lt;li&gt;Check for duplicate classes/JARs in runtime classpath.&lt;/li&gt;
  &lt;li&gt;Classify the error (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkageError&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClassCastException&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NoClassDefFoundError&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;Apply the smallest fix first: dependency alignment, loader parent change, or process isolation.&lt;/li&gt;
  &lt;li&gt;Keep a regression test that asserts class origin and classpath assumptions.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Practical rule: if the same class name appears from two different loader instances, treat it as a structural
problem, not a random runtime glitch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That workflow gives you an actionable path from stacktrace to root cause, and it keeps the &lt;strong&gt;Rule Number One&lt;/strong&gt;
practical under real production pressure.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;JVM gives you the real power to load classes property. There are huge applications like Web Servers,
Application Servers, OSGi containers, TomCat, IntelliJ, where you manage classloading.&lt;/p&gt;

&lt;p&gt;Classloading is the powerful way to manage classes and make different applications co-exist together.
Sometimes you can even use java.lang.reflect.Proxy to bind one classloader to another.&lt;/p&gt;

&lt;p&gt;But please, be careful, investigate your problems, and follow the &lt;strong&gt;Rule Number One&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/plugin-class-loaders.html&quot;&gt;Plugin Class Loaders&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/testing-plugins.html&quot;&gt;Testing Plugins&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/tools-intellij-platform-gradle-plugin-faq.html&quot;&gt;IntelliJ Platform Gradle Plugin FAQ (PathClassLoader in tests)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.jetbrains.com/platform/2024/07/intellij-platform-gradle-plugin-2-0/&quot;&gt;IntelliJ Platform Gradle Plugin 2.0 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024.2+&lt;/code&gt; migration note)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/tools-intellij-platform-gradle-plugin-dependencies-extension.html&quot;&gt;IntelliJ Platform Gradle Plugin Dependencies Extension (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;testFramework(...)&lt;/code&gt;))&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/internationalization.html&quot;&gt;Internationalization (bundle naming and lookup)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/plugin-configuration-file.html&quot;&gt;Plugin Configuration File (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resource-bundle&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/api-changes-list-2024.html&quot;&gt;IntelliJ Platform API Changes List (2024.2/testing-related notes)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="jvm" />
  
    <category term="classloading" />
  
    <category term="intellij" />
  
    <category term="plugin-development" />
  
    <category term="java" />
  
    <summary type="html">If your IntelliJ plugin works in tests but fails in production with LinkageError, ClassCastException, or plugin conflicts, you are likely hitting a classloader boundary problem. This post walks through JVM classloading fundamentals, IntelliJ&apos;s plugin classloader architecture, and practical debugging patterns to keep your plugins stable across test and runtime environments.</summary>
  
  </entry>
  
  <entry>
    <title type="html">The Cost Return of Local AI: When Does Your Hardware Pay for Itself?</title>
    <link href="https://jonnyzzz.com/blog/2026/02/09/local-ai-cost-return/" rel="alternate" type="text/html" title="The Cost Return of Local AI: When Does Your Hardware Pay for Itself?" />
    <published>2026-02-09T00:00:00+00:00</published>
    <updated>2026-02-09T00:00:00+00:00</updated>
    <id>/blog/2026/02/09/local-ai-cost-return</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/02/09/local-ai-cost-return/">&lt;p&gt;Should you buy Local AI hardware or rent cloud tokens? I’ve been running local models on an
&lt;a href=&quot;/blog/2025/11/26/junie-cage-spark/&quot;&gt;NVIDIA DGX Spark&lt;/a&gt; and a MacBook Pro M4 Max with 128GB, orchestrating fleets of
&lt;a href=&quot;/blog/2026/02/06/run-agent-multi-agent-orchestration/&quot;&gt;AI Agents&lt;/a&gt; against them. The analysis below also covers Mac Studio configurations
and dual-GPU workstations for comparison. The obvious question: &lt;strong&gt;does it actually save money
compared to Anthropic and OpenAI APIs?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We analyzed four popular setups, drawing from published benchmarks and community testing. Then
we modeled what happens when cloud prices keep falling. The answer is more nuanced – and more
interesting – than I expected.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key finding:&lt;/strong&gt; At full utilization, mid-range setups (Mac Studio M4 Max 128GB, DGX Spark)
can pay for themselves in &lt;strong&gt;1.6–8 months&lt;/strong&gt; when replacing Opus/Sonnet-class API usage – the
DGX Spark running GPT-OSS 120B breaks even in &lt;strong&gt;under 2 months&lt;/strong&gt;. But cloud API prices are
falling so fast that your spreadsheet might be wrong before your hardware arrives.&lt;/p&gt;

&lt;p&gt;All calculations below are reproducible. &lt;a href=&quot;/downloads/local-ai-payoff-calculator.py&quot;&gt;Grab the Python calculator&lt;/a&gt; and run it
yourself with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uv run local-ai-payoff-calculator.py&lt;/code&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-four-setups&quot;&gt;The Four Setups&lt;/h2&gt;

&lt;p&gt;We selected four configurations representing different price-performance tiers. All suitable
for Local AI inference in a desktop/office environment. Prices reflect Apple.com configurator
and NVIDIA retail as of Q1 2026. Electricity costs are &lt;strong&gt;explicitly excluded&lt;/strong&gt; (we address
them separately below).&lt;/p&gt;

&lt;h3 id=&quot;setup-a-mac-studio-m3-ultra--512gb&quot;&gt;Setup A: Mac Studio M3 Ultra – 512GB&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Spec&lt;/th&gt;
      &lt;th&gt;Detail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Chip&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Apple M3 Ultra, 32-core CPU, 80-core GPU, 32-core Neural Engine&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;512GB unified (819 GB/s bandwidth)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Price&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;~$9,500&lt;/strong&gt; (base $3,999 + chip upgrade + 512GB RAM)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Pricing source: &lt;a href=&quot;https://www.apple.com/shop/buy-mac/mac-studio&quot;&gt;Apple Mac Studio configurator&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The M3 Ultra’s 819 GB/s memory bandwidth is its killer feature. Token generation speed is
almost entirely memory-bandwidth bound. This is the only desktop-class machine that can run
600B+ parameter models (like DeepSeek R1 671B) entirely in memory.&lt;/p&gt;

&lt;h3 id=&quot;setup-b-mac-studio-m4-max--128gb&quot;&gt;Setup B: Mac Studio M4 Max – 128GB&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Spec&lt;/th&gt;
      &lt;th&gt;Detail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Chip&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Apple M4 Max, 16-core CPU, 40-core GPU, 16-core Neural Engine&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;128GB unified (546 GB/s bandwidth)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Price&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;~$3,500&lt;/strong&gt; (base $1,999 + chip and memory upgrades)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Pricing source: &lt;a href=&quot;https://www.apple.com/shop/buy-mac/mac-studio&quot;&gt;Apple Mac Studio configurator&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Best single-core performance of any Apple chip. Its 546 GB/s bandwidth and 128GB handle
quantized 70B models comfortably.&lt;/p&gt;

&lt;h3 id=&quot;setup-c-nvidia-dgx-spark--128gb&quot;&gt;Setup C: NVIDIA DGX Spark – 128GB&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Spec&lt;/th&gt;
      &lt;th&gt;Detail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Chip&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;NVIDIA GB10 Grace Blackwell Superchip&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;128GB LPDDR5x unified (273 GB/s bandwidth)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;AI Compute&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;1 PFLOP FP4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Price&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;$3,999&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Pricing source: &lt;a href=&quot;https://marketplace.nvidia.com/en-us/enterprise/personal-ai-supercomputers/dgx-spark/&quot;&gt;NVIDIA DGX Spark product page&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Excels at prompt processing (prefill) thanks to Blackwell tensor cores and FP4/NVFP4 support.
Its relatively lower memory bandwidth (273 GB/s) limits token generation speed, but its
&lt;a href=&quot;/blog/2025/11/26/junie-cage-spark/&quot;&gt;MoE performance is a standout&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;setup-d-dual-rtx-3090-workstation&quot;&gt;Setup D: Dual RTX 3090 Workstation&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Spec&lt;/th&gt;
      &lt;th&gt;Detail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;GPUs&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;2x NVIDIA RTX 3090 (24GB VRAM each = 48GB total)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;GPU Bandwidth&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;936 GB/s per card&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Price&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;~$3,600&lt;/strong&gt; (used 3090s ~$800 each + rest of system)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The price-performance champion for pure inference throughput within its 48GB VRAM limit.
Models must fit within GPU VRAM; larger models fall back to CPU offloading with severe
performance penalties.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;models-and-benchmarks&quot;&gt;Models and Benchmarks&lt;/h2&gt;

&lt;p&gt;All benchmarks use 4-bit quantization (Q4_K_M for GGUF, NVFP4 where available) – the
practical sweet spot for quality vs. performance. Token generation speed is single-user,
interactive decode using llama.cpp or MLX.&lt;/p&gt;

&lt;h3 id=&quot;token-generation-speed-tokenssecond&quot;&gt;Token Generation Speed (tokens/second)&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;A: M3 Ultra&lt;/th&gt;
      &lt;th&gt;B: M4 Max&lt;/th&gt;
      &lt;th&gt;C: DGX Spark&lt;/th&gt;
      &lt;th&gt;D: 2x 3090&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;LLaMA 3.1 8B Q4&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;~85&lt;/td&gt;
      &lt;td&gt;~70&lt;/td&gt;
      &lt;td&gt;~38&lt;/td&gt;
      &lt;td&gt;~120&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Qwen3 30B Q4&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;~30&lt;/td&gt;
      &lt;td&gt;~22&lt;/td&gt;
      &lt;td&gt;~20&lt;/td&gt;
      &lt;td&gt;~35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;LLaMA 3.1 70B Q4&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;~14&lt;/td&gt;
      &lt;td&gt;~8&lt;/td&gt;
      &lt;td&gt;~6&lt;/td&gt;
      &lt;td&gt;~13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;GPT-OSS 120B Q4&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;~20&lt;/td&gt;
      &lt;td&gt;~10&lt;/td&gt;
      &lt;td&gt;~50&lt;/td&gt;
      &lt;td&gt;Cannot fit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;DeepSeek R1 671B Q4&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;~17&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The DGX Spark’s GPT-OSS 120B number stands out: &lt;strong&gt;50 t/s on a $3,999 box&lt;/strong&gt;. This is the MoE
(Mixture of Experts) sweet spot – only ~20B parameters active per token, but the NVFP4
tensor cores eat it for breakfast.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sources: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/4167&quot;&gt;llama.cpp Apple Silicon discussion #4167&lt;/a&gt;,
&lt;a href=&quot;https://lmsys.org/blog/2025-10-13-nvidia-dgx-spark/&quot;&gt;LMSYS DGX Spark review&lt;/a&gt;, &lt;a href=&quot;https://www.hardware-corner.net/first-dgx-spark-llm-benchmarks/&quot;&gt;hardware-corner.net benchmarks&lt;/a&gt;,
&lt;a href=&quot;https://lmsys.org/blog/2025-11-03-gpt-oss-on-nvidia-dgx-spark/&quot;&gt;LMSYS GPT-OSS on DGX Spark&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;cloud-api-pricing&quot;&gt;Cloud API Pricing&lt;/h2&gt;

&lt;p&gt;We map each local model to a comparable cloud API tier. This mapping is inherently approximate
– a local LLaMA 70B Q4 doesn’t match Claude Sonnet 4.5 quality. But they serve similar use
cases at roughly comparable quality levels.&lt;/p&gt;

&lt;h3 id=&quot;output-token-pricing-as-of-q1-2026&quot;&gt;Output Token Pricing (as of Q1 2026)&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Provider&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Input $/MTok&lt;/th&gt;
      &lt;th&gt;Output $/MTok&lt;/th&gt;
      &lt;th&gt;Comparable Local Model&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;Claude Haiku 4.5&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;$1.00&lt;/td&gt;
      &lt;td&gt;$5.00&lt;/td&gt;
      &lt;td&gt;LLaMA 3.1 8B&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;Claude Sonnet 4.5&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;$3.00&lt;/td&gt;
      &lt;td&gt;$15.00&lt;/td&gt;
      &lt;td&gt;LLaMA 3.1 70B, Qwen3 30B&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;Claude Opus 4.5&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;$5.00&lt;/td&gt;
      &lt;td&gt;$25.00&lt;/td&gt;
      &lt;td&gt;DeepSeek R1 671B, GPT-OSS&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;GPT-4o&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;$2.50&lt;/td&gt;
      &lt;td&gt;$10.00&lt;/td&gt;
      &lt;td&gt;LLaMA 3.1 70B, Qwen3 30B&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;GPT-4o mini&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;$0.15&lt;/td&gt;
      &lt;td&gt;$0.60&lt;/td&gt;
      &lt;td&gt;LLaMA 3.1 8B&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;GPT-5.1&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;$1.25&lt;/td&gt;
      &lt;td&gt;$10.00&lt;/td&gt;
      &lt;td&gt;GPT-OSS 120B&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Sources: &lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;Anthropic API pricing&lt;/a&gt;, &lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;OpenAI pricing&lt;/a&gt;,
&lt;a href=&quot;https://www.metacto.com/blogs/anthropic-api-pricing-a-full-breakdown-of-costs-and-integration&quot;&gt;MetaCTO analysis (Dec 2025)&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-payoff-table&quot;&gt;The Payoff Table&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Payoff = Hardware Cost / Cloud Cost Per Hour&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We assume a 70/30 output/input token ratio (typical for interactive use). Weighted price per
million tokens = 0.7 x output + 0.3 x input. Tokens per hour = tokens/sec x 3600.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Setup + Model&lt;/th&gt;
      &lt;th&gt;HW Cost&lt;/th&gt;
      &lt;th&gt;Cloud $/hr&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Payoff Months&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;C: DGX Spark + GPT-OSS 120B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,999&lt;/td&gt;
      &lt;td&gt;$3.42&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;1.6&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;D: 2x3090 + LLaMA 8B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,600&lt;/td&gt;
      &lt;td&gt;$1.64&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;3.0&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;D: 2x3090 + Qwen3 30B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,600&lt;/td&gt;
      &lt;td&gt;$1.44&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;3.5&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;B: M4 Max + LLaMA 8B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,500&lt;/td&gt;
      &lt;td&gt;$0.96&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;5.1&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;C: DGX Spark + Qwen3 30B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,999&lt;/td&gt;
      &lt;td&gt;$0.82&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;6.8&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;B: M4 Max + GPT-OSS 120B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,500&lt;/td&gt;
      &lt;td&gt;$0.68&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;7.1&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;B: M4 Max + Qwen3 30B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,500&lt;/td&gt;
      &lt;td&gt;$0.61&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;7.9&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;D: 2x3090 + LLaMA 70B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,600&lt;/td&gt;
      &lt;td&gt;$0.53&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;9.4&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;A: M3 Ultra + GPT-OSS 120B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$9,500&lt;/td&gt;
      &lt;td&gt;$1.37&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;9.6&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;A: M3 Ultra + DeepSeek R1 671B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$9,500&lt;/td&gt;
      &lt;td&gt;$1.16&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;11.3&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;A: M3 Ultra + Qwen3 30B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$9,500&lt;/td&gt;
      &lt;td&gt;$1.23&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;10.7&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;C: DGX Spark + LLaMA 8B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,999&lt;/td&gt;
      &lt;td&gt;$0.52&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;10.7&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;A: M3 Ultra + LLaMA 8B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$9,500&lt;/td&gt;
      &lt;td&gt;$1.16&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;11.3&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;B: M4 Max + LLaMA 70B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,500&lt;/td&gt;
      &lt;td&gt;$0.33&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;14.8&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;C: DGX Spark + LLaMA 70B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$3,999&lt;/td&gt;
      &lt;td&gt;$0.25&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;22.6&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;A: M3 Ultra + LLaMA 70B&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$9,500&lt;/td&gt;
      &lt;td&gt;$0.57&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;23.0&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;These numbers assume &lt;strong&gt;100% utilization, 24/7&lt;/strong&gt;. Multiply by 2x for 12hr/day usage, 4x for
6hr/day, 10x for occasional use.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-sweet-spot&quot;&gt;The Sweet Spot&lt;/h2&gt;

&lt;p&gt;Three scenarios stand out:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DGX Spark + GPT-OSS 120B vs Opus-class pricing: ~1.6 months.&lt;/strong&gt; The Blackwell tensor cores
combined with MoE efficiency and NVFP4 quantization make this the fastest payoff. At 50%
utilization it’s 4 months. This is the standout finding – &lt;strong&gt;under 2 months at full
utilization&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dual RTX 3090 + small/medium models: 3–3.5 months.&lt;/strong&gt; Highest raw throughput on models
that fit in 48GB VRAM. The used GPU market makes this the cheapest entry point.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;M4 Max 128GB + 8B/30B models: 5–8 months.&lt;/strong&gt; The best balance of price, ecosystem
(MLX), silence, and capability for a single developer.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The M3 Ultra 512GB shows &lt;strong&gt;11.3 months&lt;/strong&gt; payoff for DeepSeek R1 671B (~17 t/s), making it
competitive with other mid-range scenarios. It’s the only desktop that runs these frontier-scale
models entirely in memory.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;but-wait--cloud-prices-keep-falling&quot;&gt;But Wait – Cloud Prices Keep Falling&lt;/h2&gt;

&lt;p&gt;Here’s where the story gets uncomfortable. The payoff table above treats cloud prices as
&lt;strong&gt;constant&lt;/strong&gt;. They are not.&lt;/p&gt;

&lt;p&gt;According to &lt;a href=&quot;https://epoch.ai/data-insights/llm-inference-price-trends&quot;&gt;Epoch AI research (March 2025)&lt;/a&gt;, LLM inference prices have fallen
between 9x and 900x per year depending on the benchmark, with a median decline of &lt;strong&gt;50x per
year&lt;/strong&gt;. After January 2024, the median rate accelerated to &lt;strong&gt;200x per year&lt;/strong&gt;. The &lt;a href=&quot;https://aiindex.stanford.edu/report/&quot;&gt;Stanford
HAI AI Index&lt;/a&gt; puts it starkly: GPT-3.5-level performance cost fell from $20 per
1M tokens (November 2022) to $0.07 (October 2024) – &lt;strong&gt;280x in 18 months&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;What does that do to our payoff math?&lt;/p&gt;

&lt;h3 id=&quot;risk-adjusted-payoff-months&quot;&gt;Risk-Adjusted Payoff (months)&lt;/h3&gt;

&lt;p&gt;Here’s the DGX Spark + GPT-OSS 120B (the best scenario) under different cloud price decline
rates and utilization levels:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Utilization&lt;/th&gt;
      &lt;th&gt;Constant price&lt;/th&gt;
      &lt;th&gt;25%/yr decline&lt;/th&gt;
      &lt;th&gt;50%/yr decline&lt;/th&gt;
      &lt;th&gt;80%/yr decline&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;100% (24/7)&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50% (12h/d)&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25% (6h/d)&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10% (2.4h/d)&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;And the M4 Max + Qwen3 30B (a more typical developer scenario):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Utilization&lt;/th&gt;
      &lt;th&gt;Constant price&lt;/th&gt;
      &lt;th&gt;25%/yr decline&lt;/th&gt;
      &lt;th&gt;50%/yr decline&lt;/th&gt;
      &lt;th&gt;80%/yr decline&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;100% (24/7)&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50% (12h/d)&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25% (6h/d)&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10% (2.4h/d)&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
      &lt;td&gt;never&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;“Never” means the hardware never pays for itself&lt;/strong&gt; – cumulative cloud savings converge to
a finite amount that’s less than the hardware cost. Mathematically:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Max lifetime savings = C0 / (1 - m), where m = (1 - annual_decline_rate)^(1/12)&lt;/p&gt;

  &lt;p&gt;If hardware_cost &amp;gt; max_lifetime_savings, payoff = never.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is the most dangerous finding: &lt;strong&gt;at 80% annual cloud price decline and less than 25%
utilization, most setups never break even on token economics alone.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;seven-trends-shaping-the-next-18-months&quot;&gt;Seven Trends Shaping the Next 18 Months&lt;/h2&gt;

&lt;p&gt;I track these because they directly affect whether buying Local AI hardware today is smart
or premature:&lt;/p&gt;

&lt;h3 id=&quot;1-api-price-deflation--the-biggest-threat&quot;&gt;1. API Price Deflation – The Biggest Threat&lt;/h3&gt;

&lt;p&gt;OpenAI moved from GPT-4 ($30/$60 per MTok) to GPT-4 Turbo ($10/$30), then to GPT-4o
($2.50/$10) – an 83% decline from GPT-4 to GPT-4o. DeepSeek V3.2 hit $0.28/$0.42 per
MTok – 90% below GPT-4.1. Gartner forecasts that by 2026, AI services cost will become a
chief competitive factor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impact:&lt;/strong&gt; A payoff period of 8 months today becomes 80 months if prices drop 10x.&lt;/p&gt;

&lt;h3 id=&quot;2-open-source-quality--the-biggest-tailwind&quot;&gt;2. Open-Source Quality – The Biggest Tailwind&lt;/h3&gt;

&lt;p&gt;According to &lt;a href=&quot;https://whatllm.org&quot;&gt;WhatLLM.org&lt;/a&gt; (January 2026), the gap between best open-source and
proprietary models has narrowed significantly – down from 20+ points in late 2024 to
single digits in early 2026. Open-source models now win on specific benchmarks outright.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impact:&lt;/strong&gt; Closes the “quality discount” in our calculations. A local 30B running in 2026
might genuinely match GPT-4o quality.&lt;/p&gt;

&lt;h3 id=&quot;3-hardware-depreciation--the-clock-is-ticking&quot;&gt;3. Hardware Depreciation – The Clock Is Ticking&lt;/h3&gt;

&lt;p&gt;Apple M5 launched October 2025 with 30% bandwidth improvement. M5 Ultra &lt;strong&gt;rumored&lt;/strong&gt; for mid-2026
at ~1,100 GB/s (unconfirmed, no official announcement). RTX 5090 ships at $1,999 MSRP and shows
significant throughput improvements over RTX 4090 in early community benchmarks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impact:&lt;/strong&gt; A $9,500 M3 Ultra bought today will be outperformed by an M5 Ultra at similar
price within 6–9 months.&lt;/p&gt;

&lt;h3 id=&quot;4-model-efficiency--smaller-gets-smarter&quot;&gt;4. Model Efficiency – Smaller Gets Smarter&lt;/h3&gt;

&lt;p&gt;Model distillation techniques continue advancing rapidly. Smaller models (8B-30B range) are
increasingly matching or approaching the quality of previous-generation 70B+ models through
better training and distillation methods.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impact:&lt;/strong&gt; Your hardware gets more capable over time through software alone. The M4 Max
becomes a better machine next year without changing anything.&lt;/p&gt;

&lt;h3 id=&quot;5-agentic-ai--the-utilization-multiplier&quot;&gt;5. Agentic AI – The Utilization Multiplier&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cbinsights.com/research/ai-agent-market-map-2025/&quot;&gt;CB Insights tracks 170+ AI Agent startups&lt;/a&gt; with billions in funding.
Gartner forecasts 40% of enterprise apps will have task-specific AI Agents by end of 2026. When I run
&lt;a href=&quot;/blog/2026/02/06/run-agent-multi-agent-orchestration/&quot;&gt;fleets of AI Agents&lt;/a&gt;, utilization jumps from 25% to 60–80%. That transforms
the payoff math.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impact:&lt;/strong&gt; The catch is that local models still struggle with reliable tool calling in
agentic contexts. Until that matures, the highest-value workloads stay on cloud.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;OpenClaw and Personal AI Assistants:&lt;/strong&gt; One compelling agentic use case is running personal
AI assistant bots like &lt;a href=&quot;https://openclaw.ai/&quot;&gt;OpenClaw&lt;/a&gt; (formerly ClawdBot/Moltbot). OpenClaw runs locally,
integrates with messaging services (Signal, Telegram, Discord, WhatsApp), and connects to either
cloud APIs or local LLMs via Ollama. With &lt;a href=&quot;https://dev.to/mechcloud_academy/unleashing-openclaw-the-ultimate-guide-to-local-ai-agents-for-developers-in-2026-3k0h&quot;&gt;147,000+ GitHub stars and 2 million visitors in a
week&lt;/a&gt;, it represents the “2026 year of personal agents” trend. Running these bots
24/7 on local hardware makes the utilization economics much more attractive – a DGX Spark or Mac
Studio running OpenClaw with a local 70B model is generating value around the clock, not just
during active coding sessions.&lt;/p&gt;

&lt;h3 id=&quot;6-privacy-and-compliance--the-non-financial-roi&quot;&gt;6. Privacy and Compliance – The Non-Financial ROI&lt;/h3&gt;

&lt;p&gt;For regulated industries, a single data breach can cost millions. That makes the $3,500–$9,500
hardware investment trivially justified regardless of the break-even math.&lt;/p&gt;

&lt;h3 id=&quot;7-distributed-clustering--exo-labs-changes-everything&quot;&gt;7. Distributed Clustering – EXO Labs Changes Everything&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/exo-explore/exo&quot;&gt;EXO 1.0&lt;/a&gt; with RDMA over Thunderbolt 5 (macOS 26.2) lets multiple Macs pool
memory. &lt;a href=&quot;https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5/&quot;&gt;Jeff Geerling’s benchmarks&lt;/a&gt; on a 4x M3 Ultra cluster (1.5TB total):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;1 Node (t/s)&lt;/th&gt;
      &lt;th&gt;4 Nodes EXO+RDMA (t/s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Qwen3 235B (8-bit)&lt;/td&gt;
      &lt;td&gt;19.5&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;31.9&lt;/strong&gt; (+64%)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DeepSeek V3.1 671B (8-bit)&lt;/td&gt;
      &lt;td&gt;21.1&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;32.5&lt;/strong&gt; (+54%)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Without RDMA, adding nodes actually &lt;strong&gt;decreased&lt;/strong&gt; performance. With RDMA, latency drops from
~300us to &amp;lt;50us. This means you can start with one $3,500 M4 Max, prove utilization, then add
machines incrementally – instead of betting $9,500 on a single box.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-decision-framework&quot;&gt;The Decision Framework&lt;/h2&gt;

&lt;p&gt;Combining all trends:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Factor&lt;/th&gt;
      &lt;th&gt;Direction&lt;/th&gt;
      &lt;th&gt;Net Effect on Local ROI&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;API price deflation&lt;/td&gt;
      &lt;td&gt;Hurts local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Strong negative&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Open-source quality gains&lt;/td&gt;
      &lt;td&gt;Helps local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Strong positive&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hardware depreciation&lt;/td&gt;
      &lt;td&gt;Hurts local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Moderate negative&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Model efficiency&lt;/td&gt;
      &lt;td&gt;Helps local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Strong positive&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Agentic utilization&lt;/td&gt;
      &lt;td&gt;Helps local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Conditional positive&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Privacy/compliance value&lt;/td&gt;
      &lt;td&gt;Helps local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Strong positive&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Distributed clustering&lt;/td&gt;
      &lt;td&gt;Helps local case&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Strong positive&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The two strongest forces – API price deflation and open-source quality gains – partially
cancel each other out. The decisive variable remains &lt;strong&gt;utilization&lt;/strong&gt;: local hardware wins when
it runs consistently, and AI Agent fleets may be the catalyst that makes consistent utilization
the norm.&lt;/p&gt;

&lt;h3 id=&quot;the-practical-rule&quot;&gt;The Practical Rule&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;If your setup pays back in &lt;strong&gt;&amp;lt;6 months&lt;/strong&gt; even under 50%/yr cloud price decline + realistic
utilization: &lt;strong&gt;buy it&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;If payback is &lt;strong&gt;&amp;gt;18 months&lt;/strong&gt; in the base case: treat local as a bet on &lt;strong&gt;non-price value&lt;/strong&gt;
(privacy, reliability, independence) – not pure ROI.&lt;/li&gt;
  &lt;li&gt;If your workload is compatible with cheap/batched/cached cloud: &lt;strong&gt;local ROI risk increases
substantially&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-recommendation&quot;&gt;My Recommendation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Start with the lowest viable hardware&lt;/strong&gt; – M4 Max at $3,500 or DGX Spark at $3,999. Aim
for break-even within 6 months at realistic utilization. &lt;strong&gt;Scale by clustering&lt;/strong&gt; – add a
second machine via EXO/RDMA when utilization proves out, rather than buying the most expensive
single box upfront.&lt;/p&gt;

&lt;p&gt;Reserve the M3 Ultra 512GB for teams that have already proven sustained utilization on smaller
hardware and need frontier-scale models that cannot run elsewhere.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-calculator&quot;&gt;The Calculator&lt;/h2&gt;

&lt;p&gt;All the numbers in this post come from a single Python program that you can run, modify, and
extend. It’s a &lt;a href=&quot;/downloads/local-ai-payoff-calculator.py&quot;&gt;uv-compatible script&lt;/a&gt; – no dependencies, just:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uv run local-ai-payoff-calculator.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It computes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Main payoff table (all setup x model combinations)&lt;/li&gt;
  &lt;li&gt;Risk-adjusted scenarios (with cloud price decline modeling)&lt;/li&gt;
  &lt;li&gt;Electricity cost impact analysis&lt;/li&gt;
  &lt;li&gt;JSON output for further processing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/downloads/local-ai-payoff-calculator.py&quot;&gt;Download the calculator&lt;/a&gt; and plug in your own hardware costs, throughput numbers,
and cloud pricing. The numbers will be different by the time you read this – that’s the point.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;methodology-notes&quot;&gt;Methodology Notes&lt;/h2&gt;

&lt;p&gt;A few things we explicitly chose to exclude or simplify:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Electricity excluded&lt;/strong&gt;: The dual RTX 3090 at 700W costs ~$0.105/hr – adds 20% to the
cheapest cloud equivalent. Mac Studio at 200W adds ~5%. Not nothing, but not the main
driver.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Quality mapping is approximate&lt;/strong&gt;: A quantized 70B model is not Claude Sonnet 4.5.
Cloud frontier models maintain a quality advantage for many tasks. This analysis assumes
“good enough” for your use case.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Single-user inference&lt;/strong&gt;: Batched inference (multiple users) changes economics
dramatically in favor of CUDA hardware.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Maintenance and depreciation excluded&lt;/strong&gt;: Hardware lasts 3–5 years. Resale value not
factored in.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Benchmark data sources&lt;/strong&gt;: Token speeds are composites from llama.cpp, MLX, Ollama, NVIDIA
official benchmarks, and Geerling’s repository. Numbers represent typical single-stream
decode speeds as of Q1 2026. Actual performance varies with context length, quantization
method, and framework version.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;sources-and-references&quot;&gt;Sources and References&lt;/h2&gt;

&lt;h3 id=&quot;hardware-pricing&quot;&gt;Hardware Pricing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.apple.com/shop/buy-mac/mac-studio&quot;&gt;Apple.com Mac Studio configurator&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://marketplace.nvidia.com/en-us/enterprise/personal-ai-supercomputers/dgx-spark/&quot;&gt;NVIDIA DGX Spark marketplace ($3,999 MSRP)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.microcenter.com/product/699008/nvidia-dgx-spark&quot;&gt;Micro Center DGX Spark listing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inference-benchmarks&quot;&gt;Inference Benchmarks&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/4167&quot;&gt;llama.cpp Apple Silicon discussion #4167&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/16578&quot;&gt;llama.cpp DGX Spark discussion #16578&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://lmsys.org/blog/2025-10-13-nvidia-dgx-spark/&quot;&gt;LMSYS DGX Spark in-depth review (October 2025)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://lmsys.org/blog/2025-11-03-gpt-oss-on-nvidia-dgx-spark/&quot;&gt;LMSYS GPT-OSS on DGX Spark (November 2025)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.hardware-corner.net/first-dgx-spark-llm-benchmarks/&quot;&gt;hardware-corner.net DGX Spark benchmarks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://research.aimultiple.com/dgx-spark-alternatives/&quot;&gt;AIMultiple DGX Spark analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5/&quot;&gt;Jeff Geerling: Mac Studio RDMA cluster&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/blog/how-nvidia-dgx-sparks-performance-enables-intensive-ai-tasks/&quot;&gt;NVIDIA Developer Blog: DGX Spark Performance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ollama.com/blog/nvidia-spark-performance&quot;&gt;Ollama DGX Spark Performance Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cloud-api-pricing-1&quot;&gt;Cloud API Pricing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/pricing&quot;&gt;Anthropic API pricing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;OpenAI API pricing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.metacto.com/blogs/anthropic-api-pricing-a-full-breakdown-of-costs-and-integration&quot;&gt;MetaCTO Claude pricing guide (December 2025)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://costgoat.com/pricing/claude-api&quot;&gt;CostGoat Claude API calculator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;future-trends&quot;&gt;Future Trends&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://epoch.ai/data-insights/llm-inference-price-trends&quot;&gt;Epoch AI: LLM inference price trends&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aiindex.stanford.edu/report/&quot;&gt;Stanford HAI AI Index 2025&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5/&quot;&gt;Jeff Geerling: 1.5TB VRAM Mac Studio cluster (December 2025)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/exo-explore/exo&quot;&gt;EXO Labs GitHub&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://whatllm.org&quot;&gt;WhatLLM.org model quality analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/html/2511.23455v1&quot;&gt;SOSP’25 Aegaeon paper: token-level GPU pooling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;comparative-guides&quot;&gt;Comparative Guides&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://introl.com/blog/inference-unit-economics-true-cost-per-million-tokens-guide&quot;&gt;Introl.com: Local LLM Hardware Guide 2025&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ikangai.com/the-complete-guide-to-running-llms-locally-hardware-software-and-performance-essentials/&quot;&gt;ikangai.com: Complete Guide to Running LLMs Locally&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;This analysis should be refreshed quarterly – hardware (M5 Ultra expected mid-2026), API
pricing (trending sharply downward), and open-source model quality (trending sharply upward)
are all moving targets.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: Based on publicly available benchmark data and pricing as of Q1 2026. Actual
performance varies. No financial relationship with any hardware or cloud provider. Not
financial advice.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have questions or corrections? Reach out on
&lt;a href=&quot;https://www.linkedin.com/in/jonnyzzz/&quot;&gt;LinkedIn&lt;/a&gt; or
&lt;a href=&quot;https://x.com/jonnyzzz&quot;&gt;Twitter/X&lt;/a&gt;. Let’s compare notes.&lt;/em&gt;&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="local-ai" />
  
    <category term="ai-agents" />
  
    <category term="hardware" />
  
    <category term="ai-coding" />
  
    <category term="llm" />
  
    <category term="cost-analysis" />
  
    <summary type="html">Should you buy Local AI hardware or rent cloud tokens? We analyzed four popular setups, built a Python calculator, and discovered that the ground is shifting faster than any spreadsheet can keep up.</summary>
  
  </entry>
  
  <entry>
    <title type="html">run-agent.sh: Orchestrating Dozens of AI Agents from Your Terminal</title>
    <link href="https://jonnyzzz.com/blog/2026/02/06/run-agent-multi-agent-orchestration/" rel="alternate" type="text/html" title="run-agent.sh: Orchestrating Dozens of AI Agents from Your Terminal" />
    <published>2026-02-06T00:00:00+00:00</published>
    <updated>2026-02-06T00:00:00+00:00</updated>
    <id>/blog/2026/02/06/run-agent-multi-agent-orchestration</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/02/06/run-agent-multi-agent-orchestration/">&lt;p&gt;I’ve been running AI agents on codebases for a while now. One agent is useful.
Two agents can review each other’s work. But &lt;strong&gt;dozens of agents working in parallel&lt;/strong&gt;
on the same codebase – that’s where things get interesting. That’s what
&lt;a href=&quot;https://run-agent.jonnyzzz.com/&quot;&gt;run-agent.sh&lt;/a&gt; does.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/run-agent-logo.png&quot; alt=&quot;run-agent.sh logo&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;When you run a single AI agent on a task, you get one perspective, one approach,
one shot at getting it right. The agent finishes, you review the output, and if
it missed something you start over.&lt;/p&gt;

&lt;p&gt;What I wanted was a &lt;strong&gt;development team made of AI agents&lt;/strong&gt; – one that researches
the codebase, another that implements changes, a third that reviews the code, and
a fourth that runs tests. All working simultaneously. All coordinated.&lt;/p&gt;

&lt;p&gt;The challenge: AI agents don’t naturally coordinate. Each one starts fresh with
no knowledge of what the others are doing. They overwrite each other’s changes.
They duplicate work. They have no way to say “I found a blocker” or “this task
is done.”&lt;/p&gt;

&lt;h2 id=&quot;the-solution-two-files&quot;&gt;The Solution: Two Files&lt;/h2&gt;

&lt;p&gt;The entire framework is two files:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://run-agent.jonnyzzz.com/run-agent.sh&quot;&gt;run-agent.sh&lt;/a&gt;&lt;/strong&gt; – a unified
shell script that launches Claude, Codex, or Gemini with full isolation. Each
invocation gets its own run folder with the exact prompt, full stdout/stderr,
PID tracking, and exit codes. Everything is captured. Nothing is lost.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://run-agent.jonnyzzz.com/THE_PROMPT_v5.md&quot;&gt;THE_PROMPT_v5.md&lt;/a&gt;&lt;/strong&gt; – a
project-independent orchestration workflow that defines 13 stages and 7 agent
roles. This is the playbook that turns raw LLMs into a coordinated team.&lt;/p&gt;

&lt;p&gt;Both files are designed to work &lt;strong&gt;outside your project sources&lt;/strong&gt;. The orchestration
lives in its own directory – your codebase stays clean.&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How It Works&lt;/h2&gt;

&lt;p&gt;The entry point is always an &lt;strong&gt;Orchestrator&lt;/strong&gt; agent. You give it a task and point
it at your repo. It reads &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;THE_PROMPT_v5.md&lt;/code&gt; and starts spawning sub-agents:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run-agent.sh claude /path/to/your/repo prompt.md
./run-agent.sh codex /path/to/your/repo prompt.md
./run-agent.sh gemini /path/to/your/repo prompt.md
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Each agent gets a &lt;strong&gt;fixed role&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Research&lt;/strong&gt; – explores the codebase without making changes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Implementation&lt;/strong&gt; – writes code and tests&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Review&lt;/strong&gt; – performs code review and quality checks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test&lt;/strong&gt; – runs tests and verifies changes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Debug&lt;/strong&gt; – investigates failures and proposes fixes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Monitor&lt;/strong&gt; – watches for stalled agents and restarts them&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The orchestrator decides which agents to spawn, assigns tasks, and advances
through the 13 stages: from initial cleanup and research, through implementation
and quality gates, all the way to commit, push, and code review.&lt;/p&gt;

&lt;h2 id=&quot;the-message-bus&quot;&gt;The Message Bus&lt;/h2&gt;

&lt;p&gt;The key insight that makes multi-agent coordination work is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MESSAGE-BUS.md&lt;/code&gt; –
a file-based, &lt;strong&gt;append-only trace log&lt;/strong&gt;. Every agent reads and writes to it.&lt;/p&gt;

&lt;p&gt;No databases. No message queues. No infrastructure. Just a markdown file.&lt;/p&gt;

&lt;p&gt;Agents use structured message types to communicate:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;FACT&lt;/strong&gt; – concrete results (test counts, commit hashes)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PROGRESS&lt;/strong&gt; – in-flight status updates&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DECISION&lt;/strong&gt; – policy choices with rationale&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;REVIEW&lt;/strong&gt; – structured code review feedback&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ERROR&lt;/strong&gt; – failures that block progress&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The orchestrator reads the bus to decide what to do next. When an implementation
agent finishes, it posts a FACT. The orchestrator sees it and spawns review agents.
When reviewers approve, the orchestrator advances to testing. If a test fails,
an ERROR gets posted, and the orchestrator spawns a debug agent.&lt;/p&gt;

&lt;p&gt;It’s simple, it’s traceable, and it works.&lt;/p&gt;

&lt;h2 id=&quot;full-traceability&quot;&gt;Full Traceability&lt;/h2&gt;

&lt;p&gt;Every agent run creates an isolated folder under &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;runs/&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;runs/
  run_20260206-143000-12345/
    prompt.md             # exact prompt sent to the agent
    agent-stdout.txt      # everything the agent produced
    agent-stderr.txt      # errors and warnings
    cwd.txt               # working directory, command, exit code
    run-agent.sh          # copy of the runner for reproducibility
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When something goes wrong – and with dozens of agents, something always goes
wrong – you can trace exactly what each agent was told, what it did, and why
it failed. No “what did the AI do?” mysteries.&lt;/p&gt;

&lt;h2 id=&quot;working-outside-your-project&quot;&gt;Working Outside Your Project&lt;/h2&gt;

&lt;p&gt;A design choice I’m particularly happy with: the orchestration runs in its own
directory, completely separate from your project sources.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;projects/
  my-app/
    fix-auth-bug/               # task directory
      THE_PROMPT_v5.md          # orchestration workflow
      run-agent.sh              # agent runner
      MESSAGE-BUS.md            # swarm communication
      runs/                     # all agent runs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Each task gets its own workspace with independent runs, message bus, and issue
tracking. You can run multiple tasks on the same project in parallel. Your
project repo stays clean – no orchestration artifacts mixed in.&lt;/p&gt;

&lt;h2 id=&quot;quick-start&quot;&gt;Quick Start&lt;/h2&gt;

&lt;p&gt;Give this prompt to any AI agent (Claude, Codex, or Gemini):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Download and follow the orchestration workflow from:
- https://run-agent.jonnyzzz.com/run-agent.sh
- https://run-agent.jonnyzzz.com/THE_PROMPT_v5.md

Apply it to the project at: /path/to/your/repo

Set up the working directory as:
  projects/&amp;lt;project-name&amp;gt;/&amp;lt;task-name&amp;gt;/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The agent downloads the files, sets up the workspace, and starts orchestrating.
All orchestration files are published at
&lt;a href=&quot;https://run-agent.jonnyzzz.com/&quot;&gt;run-agent.jonnyzzz.com&lt;/a&gt; under the
Apache License 2.0.&lt;/p&gt;

&lt;h2 id=&quot;agent-isolation-with-git-forks&quot;&gt;Agent Isolation with Git Forks&lt;/h2&gt;

&lt;p&gt;Each agent needs its own workspace to avoid stepping on other agents’ changes.
I use the &lt;a href=&quot;/blog/2026/02/02/git-fork-pattern/&quot;&gt;git fork pattern&lt;/a&gt;
for this – full checkouts that share objects with the original repository.
Minimal disk overhead, full git functionality, true independence.&lt;/p&gt;

&lt;p&gt;The orchestrator tells each agent to fork the repo before starting work.
When the agent is done, the changes get merged back. Simple, reliable,
scales to any number of agents.&lt;/p&gt;

&lt;h2 id=&quot;mcp-steroid-integration&quot;&gt;MCP Steroid Integration&lt;/h2&gt;

&lt;p&gt;The framework works well with &lt;a href=&quot;https://mcp-steroid.jonnyzzz.com/&quot;&gt;MCP Steroid&lt;/a&gt;
for IDE-level quality gates. Before any commit lands, agents must pass through
real IDE inspections – no new warnings, no new errors, compilation must succeed.
The combination of multi-agent orchestration and IDE integration is where things
get really powerful.&lt;/p&gt;

&lt;p&gt;An orchestrator can spawn a review agent that opens the project in IntelliJ via
MCP Steroid, runs inspections, and posts the results back to the message bus.
If the review finds issues, the orchestrator spawns a fix agent. The loop
continues until the code is clean.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next&lt;/h2&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;THE_PROMPT_v5.md&lt;/code&gt; is already at version 5 – the workflow keeps evolving
as I learn what works and what doesn’t with real projects. The next areas I’m
exploring are better conflict resolution when multiple implementation agents
touch the same files, and tighter integration between the message bus and IDE
quality gates.&lt;/p&gt;

&lt;p&gt;The code is on &lt;a href=&quot;https://github.com/jonnyzzz/run-agent&quot;&gt;GitHub&lt;/a&gt;. Try it on a
real project and see what a swarm of AI agents can do.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Questions? Want to share how you’re orchestrating AI agents?&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/in/jonnyzzz/&quot;&gt;Follow me on LinkedIn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/jonnyzzz&quot;&gt;Follow me on X (Twitter)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jonnyzzz.com/ai/&quot;&gt;More AI agent patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="ai-agents" />
  
    <category term="ai-coding" />
  
    <category term="workflow" />
  
    <category term="dev-tools" />
  
    <category term="orchestration" />
  
    <summary type="html">How I built a shell-based orchestration framework that launches dozens of AI agents in parallel to research, implement, review, and test code changes</summary>
  
  </entry>
  
  <entry>
    <title type="html">Git Fork Pattern: Full Checkouts Without the Bloat</title>
    <link href="https://jonnyzzz.com/blog/2026/02/02/git-fork-pattern/" rel="alternate" type="text/html" title="Git Fork Pattern: Full Checkouts Without the Bloat" />
    <published>2026-02-02T00:00:00+00:00</published>
    <updated>2026-02-02T00:00:00+00:00</updated>
    <id>/blog/2026/02/02/git-fork-pattern</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/02/02/git-fork-pattern/">&lt;p&gt;I’ve been working with multiple AI agents on the same codebase, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git worktree&lt;/code&gt; kept getting in the way.
The same branch can’t be checked out in multiple worktrees. Some git operations don’t work well with worktrees.
&lt;strong&gt;So I stopped using worktrees entirely.&lt;/strong&gt; Instead, I’m using full git checkouts that share objects with the
original repository. &lt;strong&gt;Full git functionality, minimal disk usage.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-problem-with-git-worktree&quot;&gt;The Problem with Git Worktree&lt;/h2&gt;

&lt;p&gt;Git worktree is useful for quick parallel work, but it has limitations that become painful when you’re
orchestrating multiple AI agents or just need full git flexibility:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Can’t checkout the same branch twice&lt;/strong&gt; - Want two agents working on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main&lt;/code&gt;? Can’t do it with worktrees.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limited git operations&lt;/strong&gt; - Some rebase operations, submodules, and other features behave differently.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tool confusion&lt;/strong&gt; - IDEs and git tools sometimes don’t handle worktrees well.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tied to main repo&lt;/strong&gt; - Worktrees are dependent on the main repository structure.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you’re running &lt;a href=&quot;https://jonnyzzz.com/MULTI-AGENT.md&quot;&gt;multi-agent workflows&lt;/a&gt; or just need multiple
independent checkouts, these constraints become blockers.&lt;/p&gt;

&lt;h2 id=&quot;the-solution-git-alternates&quot;&gt;The Solution: Git Alternates&lt;/h2&gt;

&lt;p&gt;Git has a lesser-known feature called &lt;strong&gt;alternates&lt;/strong&gt; - you can tell one repository to use another
repository’s object database. This means:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create as many full checkouts as you want&lt;/li&gt;
  &lt;li&gt;Each checkout is a complete, independent git repository&lt;/li&gt;
  &lt;li&gt;Objects (commits, trees, blobs) are shared via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.git/objects/info/alternates&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;New commits are stored locally, existing objects are read from the source&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Full git functionality, no worktree limitations&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I tested this approach with our 25-year-old monorepo, and it works perfectly. Multiple agents can now
work independently, each in their own full checkout, sharing the same object database.&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How It Works&lt;/h2&gt;

&lt;p&gt;The implementation is straightforward. Here’s what happens:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Original repository&lt;/span&gt;
~/projects/myrepo/.git/objects  &lt;span class=&quot;c&quot;&gt;# Contains all git objects&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# New fork&lt;/span&gt;
~/projects/myrepo-fork/.git/objects/info/alternates
&lt;span class=&quot;c&quot;&gt;# Contains: /Users/username/projects/myrepo/.git/objects&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Result:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# - Fork reads objects from original&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# - Fork writes new objects locally&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# - Both are independent repositories&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When git needs an object, it checks the local &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.git/objects&lt;/code&gt; first, then checks the paths listed
in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alternates&lt;/code&gt; file. It’s transparent and works with all git operations.&lt;/p&gt;

&lt;h2 id=&quot;the-implementation&quot;&gt;The Implementation&lt;/h2&gt;

&lt;p&gt;The implementation is just 5 steps:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1. Create and initialize new repository&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /path/to/fork &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /path/to/fork &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; git init

&lt;span class=&quot;c&quot;&gt;# 2. Set up object sharing (use absolute path)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; .git/objects/info
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/absolute/path/to/source/.git/objects&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; .git/objects/info/alternates

&lt;span class=&quot;c&quot;&gt;# 3. Copy git config (inherits remotes)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cp&lt;/span&gt; /absolute/path/to/source/.git/config .git/config

&lt;span class=&quot;c&quot;&gt;# 4. Add parent remote and fetch&lt;/span&gt;
git remote add parent /absolute/path/to/source
git fetch parent

&lt;span class=&quot;c&quot;&gt;# 5. Checkout branch (track from parent)&lt;/span&gt;
git checkout &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; main parent/main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Done. You now have &lt;strong&gt;two remotes&lt;/strong&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;origin&lt;/code&gt; (from config) pointing to the real remote, and
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parent&lt;/code&gt; pointing to your local source repository.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://jonnyzzz.com/GIT-FORK.md&quot;&gt;GIT-FORK.md&lt;/a&gt; for complete documentation.&lt;/p&gt;

&lt;h2 id=&quot;two-remotes-pattern&quot;&gt;Two Remotes Pattern&lt;/h2&gt;

&lt;p&gt;When you copy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.git/config&lt;/code&gt;, you inherit the original repository’s remotes. Then you add a second
remote for the local parent:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;origin&lt;/strong&gt; (from config) → Real remote (GitHub, etc.) - push, pull, create PRs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;parent&lt;/strong&gt; (added manually) → Local source repo - sync uncommitted changes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is powerful for multi-agent workflows:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Working in fork&lt;/span&gt;
git commit &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;feature work&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Get latest from parent (before it&apos;s pushed anywhere)&lt;/span&gt;
git fetch parent
git merge parent/main

&lt;span class=&quot;c&quot;&gt;# Push to real remote&lt;/span&gt;
git push origin feature-branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Agents can share work through the parent repository, then independently push to origin when ready.&lt;/p&gt;

&lt;h2 id=&quot;disk-usage&quot;&gt;Disk Usage&lt;/h2&gt;

&lt;p&gt;Actual numbers from testing:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Original repo:     150 MB
Normal clone:      150 MB
Git fork:          ~5 MB (only new commits)
Git worktree:      ~5 MB (but with limitations)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The git fork gives you the disk efficiency of worktrees &lt;strong&gt;plus&lt;/strong&gt; the full functionality of a
complete repository, &lt;strong&gt;plus&lt;/strong&gt; access to both local and remote changes.&lt;/p&gt;

&lt;h2 id=&quot;ai-agent-integration&quot;&gt;AI Agent Integration&lt;/h2&gt;

&lt;p&gt;This pattern works exceptionally well with AI agents. When I orchestrate multiple agents on the
same codebase, I just tell them:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Agent, fork my git repository as suggested in GIT-FORK.md
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Agents understand this pattern and implement the 5 steps automatically. Each agent gets its own
fork with:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Full git access - create branches, rebase, merge, everything works&lt;/li&gt;
  &lt;li&gt;Shared objects - no disk space wasted&lt;/li&gt;
  &lt;li&gt;True independence - complete repository, no worktree constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I added &lt;a href=&quot;https://jonnyzzz.com/GIT-FORK.md&quot;&gt;GIT-FORK.md&lt;/a&gt; to my skill files alongside
&lt;a href=&quot;https://jonnyzzz.com/RLM.md&quot;&gt;RLM.md&lt;/a&gt; and &lt;a href=&quot;https://jonnyzzz.com/MULTI-AGENT.md&quot;&gt;MULTI-AGENT.md&lt;/a&gt;.
Agents read it and implement the pattern without additional instructions.&lt;/p&gt;

&lt;h2 id=&quot;testing-and-validation&quot;&gt;Testing and Validation&lt;/h2&gt;

&lt;p&gt;I tested this extensively:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Multiple forks&lt;/strong&gt; - Created 5+ forks from the same source, all working independently&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;All git operations&lt;/strong&gt; - Commit, branch, merge, rebase, cherry-pick - everything works&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Object sharing&lt;/strong&gt; - Verified that shared objects aren’t duplicated (checked with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;du -sh .git/objects&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tool compatibility&lt;/strong&gt; - IntelliJ, VSCode, git CLI, git GUI tools - all work normally&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;25-year-old monorepo&lt;/strong&gt; - Works with large, complex repositories&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key insight: &lt;strong&gt;this is just a normal git repository with an optimization&lt;/strong&gt;. Tools don’t need
to know about alternates, they just work.&lt;/p&gt;

&lt;h2 id=&quot;important-notes&quot;&gt;Important Notes&lt;/h2&gt;

&lt;p&gt;A few things to keep in mind:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Absolute paths&lt;/strong&gt; - The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alternates&lt;/code&gt; file must contain absolute paths, not relative paths&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Source availability&lt;/strong&gt; - The source repository must remain available. If you delete it, forks lose shared objects&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Two remotes&lt;/strong&gt; - Copying config gives you &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;origin&lt;/code&gt;, then you add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parent&lt;/code&gt; manually&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Track parent&lt;/strong&gt; - Checkout from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parent/branch&lt;/code&gt;, not &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;origin/branch&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Garbage collection&lt;/strong&gt; - Each repository runs &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git gc&lt;/code&gt; independently, which is usually fine&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Not for distribution&lt;/strong&gt; - This is for local development, not for sharing repos with others&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The two-remote pattern means you can:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git fetch parent      &lt;span class=&quot;c&quot;&gt;# Get local uncommitted changes&lt;/span&gt;
git fetch origin      &lt;span class=&quot;c&quot;&gt;# Get pushed changes from team&lt;/span&gt;
git push origin main  &lt;span class=&quot;c&quot;&gt;# Push your work to team&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;the-pattern-in-practice&quot;&gt;The Pattern in Practice&lt;/h2&gt;

&lt;p&gt;Here’s my typical workflow now:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Main repository&lt;/strong&gt; - My primary working copy at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/projects/myrepo&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tell agent&lt;/strong&gt; - “Fork my git as suggested in GIT-FORK.md”&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Agent works&lt;/strong&gt; - Creates fork, does work, full git capabilities&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cleanup&lt;/strong&gt; - Delete fork when done, no impact on main repository&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Some forks last minutes, some last days. The flexibility is what matters - forks are cheap (5MB),
fully functional, and agents know how to create them.&lt;/p&gt;

&lt;h2 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;/h2&gt;

&lt;p&gt;The git fork pattern enables true parallel development with AI agents. Instead of carefully
orchestrating which agent works where and managing worktree constraints, I just:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spin up agent with its own fork&lt;/li&gt;
  &lt;li&gt;Agent works independently&lt;/li&gt;
  &lt;li&gt;Agent completes task&lt;/li&gt;
  &lt;li&gt;Results are integrated back&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The pattern scales to any number of agents. I’ve had 5+ agents working simultaneously, each in
their own fork, no conflicts, no limitations.&lt;/p&gt;

&lt;p&gt;For solo development, this is useful too. Want to try a risky refactoring without branching? Fork
it. Want to test something while keeping your main checkout clean? Fork it. Each fork is cheap and
fully functional.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;

&lt;p&gt;The complete pattern is in &lt;a href=&quot;https://jonnyzzz.com/GIT-FORK.md&quot;&gt;GIT-FORK.md&lt;/a&gt; - just 5 steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create and initialize fork&lt;/li&gt;
  &lt;li&gt;Set up alternates file (absolute path)&lt;/li&gt;
  &lt;li&gt;Copy git config&lt;/li&gt;
  &lt;li&gt;Add remote and fetch&lt;/li&gt;
  &lt;li&gt;Checkout branch&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you’re working with AI agents, just reference GIT-FORK.md and they’ll implement it. If you’re
doing it manually, the commands are straightforward - see the doc for exact syntax.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next&lt;/h2&gt;

&lt;p&gt;I’m now exploring how to chain forks - creating a fork from a fork. This could enable interesting
multi-level agent hierarchies where parent agents spawn child agents, each with their own workspace.&lt;/p&gt;

&lt;p&gt;The git alternates mechanism has been in git for years, but it’s not widely used. With AI agents
becoming primary users of development tools, patterns like this become more important. &lt;strong&gt;Tools must
now be optimized for agentic consumption.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you’re orchestrating AI agents or just want more flexibility than git worktree provides, try the
git fork pattern. It’s what I use every day now.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Questions? Experiments? Let me know how the git fork pattern works for you.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/in/jonnyzzz/&quot;&gt;Follow me on LinkedIn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/jonnyzzz&quot;&gt;Follow me on X (Twitter)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jonnyzzz.com/ai/&quot;&gt;Check out more AI agent patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="git" />
  
    <category term="dev-tools" />
  
    <category term="ai-agents" />
  
    <category term="workflow" />
  
    <summary type="html">Why I stopped using git worktree and switched to full checkouts with shared objects</summary>
  
  </entry>
  
  <entry>
    <title type="html">Russian Loto with AI Celebrity Voices</title>
    <link href="https://jonnyzzz.com/blog/2026/02/01/russian-loto-ai-voices/" rel="alternate" type="text/html" title="Russian Loto with AI Celebrity Voices" />
    <published>2026-02-01T00:00:00+00:00</published>
    <updated>2026-02-01T00:00:00+00:00</updated>
    <id>/blog/2026/02/01/russian-loto-ai-voices</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/02/01/russian-loto-ai-voices/">&lt;p&gt;Hey Siri, can you count from 1 to 90 in random order? Siri could not. But Russian Loto absolutely
needs it: a caller shuffles 1-90 and announces each number as people mark their tickets.&lt;/p&gt;

&lt;p&gt;If you never played Loto/Bingo, this explainer shows the call-and-mark loop:
&lt;a href=&quot;https://www.youtube.com/watch?v=H1tQs2vXnQg&quot;&gt;Learn Numbers Playing Lotto (Bingo) (Games in Russian for complete beginners)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I challenged Claude to build the game in 10 minutes. Then, in the next 20 minutes, I had Qwen TTS
running locally on my Mac with AI celebrity voices. It was fast to invent, and it turned into
great family fun.&lt;/p&gt;

&lt;p&gt;The result: &lt;a href=&quot;https://github.com/jonnyzzz/jonnyzzz-loto&quot;&gt;jonnyzzz-loto&lt;/a&gt; — a Russian Loto game where
12 AI-generated celebrity voices announce numbers with character-specific jokes.&lt;/p&gt;

&lt;h2 id=&quot;the-problem-with-real-loto&quot;&gt;The Problem with Real Loto&lt;/h2&gt;

&lt;p&gt;Family gatherings with Russian Loto have a problem: the person calling numbers gets bored. They
read monotonously. The game becomes a chore. What if the announcer was actually entertaining?&lt;/p&gt;

&lt;p&gt;The obvious solution: record celebrity-like voice samples and use voice cloning. But that requires
finding clean audio samples, dealing with licensing concerns, and building a pipeline for each
celebrity. Too much work for a weekend prototype.&lt;/p&gt;

&lt;h2 id=&quot;qwen3-tts-and-voicedesign&quot;&gt;Qwen3-TTS and VoiceDesign&lt;/h2&gt;

&lt;p&gt;Alibaba’s &lt;a href=&quot;https://huggingface.co/Qwen/Qwen2.5-Omni-3B&quot;&gt;Qwen3-TTS&lt;/a&gt; changed everything. This
open-source model (Apache 2.0) has a fascinating capability called VoiceDesign — instead of
cloning a voice from audio samples, you describe the voice in text and the model generates it.
That is exactly what rapid prototyping needs: a prompt, a quick run, a new character.&lt;/p&gt;

&lt;p&gt;No samples needed. Just a text description like:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“A deep elderly male Russian voice, slow deliberate speech with long pauses, authoritative
Soviet leader tone, slight speech impediment”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And outcomes something that sounds like Brezhnev. Not a clone — but a convincing character voice
that captures the essence.&lt;/p&gt;

&lt;h2 id=&quot;the-tech-stack&quot;&gt;The Tech Stack&lt;/h2&gt;

&lt;p&gt;The project runs entirely locally on Mac with Apple Silicon, optimized for short iteration loops:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Setup (creates venv, installs dependencies)&lt;/span&gt;
./setup_qwen_mac.sh

&lt;span class=&quot;c&quot;&gt;# Run with AI voices&lt;/span&gt;
uv run python loto.py &lt;span class=&quot;nt&quot;&gt;--qwen&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Stack:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Python with &lt;a href=&quot;https://github.com/astral-sh/uv&quot;&gt;uv&lt;/a&gt; package manager&lt;/li&gt;
  &lt;li&gt;Qwen3-TTS for speech synthesis&lt;/li&gt;
  &lt;li&gt;MPS (Metal Performance Shaders) for GPU acceleration on Apple Silicon&lt;/li&gt;
  &lt;li&gt;pygame for audio playback&lt;/li&gt;
  &lt;li&gt;VoiceDesign model for text-to-voice-description synthesis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The setup script handles PyTorch with MPS support, the transformers library, and audio
dependencies. First run downloads the model (~3GB).&lt;/p&gt;

&lt;h2 id=&quot;12-celebrity-voices-random-pick-claude-generated&quot;&gt;12 Celebrity Voices Random Pick (Claude-Generated)&lt;/h2&gt;

&lt;p&gt;Each character has a unique voice description and personality:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Character&lt;/th&gt;
      &lt;th&gt;Voice Description&lt;/th&gt;
      &lt;th&gt;Style&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Leonid Brezhnev&lt;/td&gt;
      &lt;td&gt;Deep elderly male, slow deliberate speech, Soviet gravitas&lt;/td&gt;
      &lt;td&gt;Turns everything into five-year plan references&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Maxim Galkin&lt;/td&gt;
      &lt;td&gt;Theatrical, energetic showman, perfect diction&lt;/td&gt;
      &lt;td&gt;Game show host enthusiasm&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Alla Pugacheva&lt;/td&gt;
      &lt;td&gt;Mature female, pop diva, dramatic pauses&lt;/td&gt;
      &lt;td&gt;Primadonna drama for every number&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Vinni-Puh (Evgeny Leonov)&lt;/td&gt;
      &lt;td&gt;Warm, friendly, childlike wonder&lt;/td&gt;
      &lt;td&gt;Honey and friendship references&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Vladimir Zhirinovsky&lt;/td&gt;
      &lt;td&gt;Passionate, loud, political fervor&lt;/td&gt;
      &lt;td&gt;Makes everything a political statement&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Monetochka&lt;/td&gt;
      &lt;td&gt;Young female, indie pop, Gen-Z slang&lt;/td&gt;
      &lt;td&gt;“Это вайб!” for random numbers&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Korol i Shut (Gorshok)&lt;/td&gt;
      &lt;td&gt;Theatrical punk rock, horror imagery&lt;/td&gt;
      &lt;td&gt;Gothic humor, Friday the 13th&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Vladimir Vysotsky&lt;/td&gt;
      &lt;td&gt;Raspy, intense, poetic bard&lt;/td&gt;
      &lt;td&gt;Every number becomes existential&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sergey Shnurov (Leningrad)&lt;/td&gt;
      &lt;td&gt;Rock provocateur, irreverent, mocking&lt;/td&gt;
      &lt;td&gt;Makes fun of the game itself&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Filipp Kirkorov&lt;/td&gt;
      &lt;td&gt;Grandiose pop king, over-the-top&lt;/td&gt;
      &lt;td&gt;Everything is a grand celebration&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Grigory Leps&lt;/td&gt;
      &lt;td&gt;Rock ballad, emotional, gravelly&lt;/td&gt;
      &lt;td&gt;Dramatic weight to each number&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Nikolay Baskov&lt;/td&gt;
      &lt;td&gt;Operatic tenor, polished, charming&lt;/td&gt;
      &lt;td&gt;Treats Loto like opera&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;character-specific-jokes&quot;&gt;Character-Specific Jokes&lt;/h2&gt;

&lt;p&gt;The magic isn’t just in the voices — each character has jokes tailored to specific numbers. Here
are some examples:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Brezhnev on 5:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Пять... Пятилетка! Выполним и перевыполним план!
(Five... Five-year plan! We will fulfill and exceed the plan!)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Gorshok (Korol i Shut) on 13:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Тринадцать! Моё любимое число! Ха-ха-ха! Пятница тринадцатое!
(Thirteen! My favorite number! Ha-ha-ha! Friday the 13th!)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Zhirinovsky on any number:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Это число... это символ нашей великой страны!
(This number... this is a symbol of our great country!)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Monetochka on 69:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ой, это тот самый мем... Найс!
(Oh, that&apos;s that meme... Nice!)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The character definitions live in Python dataclasses with voice descriptions, typical phrases,
and number-specific joke mappings.&lt;/p&gt;

&lt;h2 id=&quot;how-voicedesign-actually-works&quot;&gt;How VoiceDesign Actually Works&lt;/h2&gt;

&lt;p&gt;Traditional TTS voice cloning needs audio samples. VoiceDesign takes a different approach:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;voice_description&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
A deep elderly male Russian voice speaking with
slow deliberate speech and long dramatic pauses.
Authoritative Soviet leader tone with slight
speech impediment characteristic of late period.
&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# The model generates voice parameters from the description
# No audio samples required
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The model was trained to understand voice characteristics from text and synthesize matching
speech. It’s not perfect — sometimes the voices drift across utterances. But for a game where
each number is a separate audio clip, it works well.&lt;/p&gt;

&lt;p&gt;The Russian language support is surprisingly good. Qwen handles Cyrillic text natively, and the
pronunciation is close enough that native speakers recognize the character archetypes.&lt;/p&gt;

&lt;h2 id=&quot;noise-detection-making-it-interactive&quot;&gt;Noise Detection: Making It Interactive&lt;/h2&gt;

&lt;p&gt;The game includes an experimental feature: ambient noise detection. It listens to the room and
reacts:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# When the room gets quiet, repeat the last number
# Uses exponential backoff to get attention
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ambient_noise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;repeat_last_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;backoff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This makes the game feel more alive — when people are talking and not paying attention, the AI
announcer waits. When it gets quiet, it calls the next number or repeats. Like a patient game
master.&lt;/p&gt;

&lt;h2 id=&quot;running-the-game&quot;&gt;Running the Game&lt;/h2&gt;

&lt;p&gt;Basic usage:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Install dependencies&lt;/span&gt;
./setup_qwen_mac.sh

&lt;span class=&quot;c&quot;&gt;# Run with AI voices (first run generates all audio clips)&lt;/span&gt;
uv run python loto.py &lt;span class=&quot;nt&quot;&gt;--qwen&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Run with pre-generated voices (faster startup)&lt;/span&gt;
uv run python loto.py &lt;span class=&quot;nt&quot;&gt;--qwen&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--cache&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Select specific character&lt;/span&gt;
uv run python loto.py &lt;span class=&quot;nt&quot;&gt;--qwen&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--character&lt;/span&gt; brezhnev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;First run takes a while — it generates audio for all numbers (1-90) for the selected character.
Subsequent runs with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--cache&lt;/code&gt; start instantly.&lt;/p&gt;

&lt;h2 id=&quot;performance-on-apple-silicon&quot;&gt;Performance on Apple Silicon&lt;/h2&gt;

&lt;p&gt;On M1/M2/M3 Macs, the MPS backend provides decent performance:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Audio generation: ~2-3 seconds per number&lt;/li&gt;
  &lt;li&gt;First run (90 numbers): ~3-4 minutes per character&lt;/li&gt;
  &lt;li&gt;Cached playback: instant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For comparison, CPU-only inference is 5-10x slower. The MPS optimization in PyTorch makes local
AI TTS practical.&lt;/p&gt;

&lt;h2 id=&quot;lessons-learned&quot;&gt;Lessons Learned&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Family Fun&lt;/strong&gt; is easy to achieve. Just a suggent idea gets much easier to implement.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VoiceDesign is powerful but inconsistent.&lt;/strong&gt; The same voice description can produce slightly
different voices across runs. For a game, this adds variety. For production TTS, you’d want more
control.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Character design matters more than voice quality.&lt;/strong&gt; A mediocre voice with great jokes is more
entertaining than a perfect voice reading numbers monotonously. The character personalities
carry the experience.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;#LocalAI for fun projects is here.&lt;/strong&gt; No API keys, no cloud costs, no latency. Models like
Qwen3-TTS make creative voice projects accessible to anyone with a decent Mac.&lt;/p&gt;

&lt;h2 id=&quot;try-it&quot;&gt;Try It&lt;/h2&gt;

&lt;p&gt;The code is at &lt;a href=&quot;https://github.com/jonnyzzz/jonnyzzz-loto&quot;&gt;github.com/jonnyzzz/jonnyzzz-loto&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Add your own characters. Improve the jokes. Make Brezhnev more authentic. The voice description
format is simple enough that you can experiment without ML expertise.&lt;/p&gt;

&lt;p&gt;And if you have a better joke for number 77 (семьдесят семь) — submit a PR.&lt;/p&gt;

&lt;p&gt;Find me on &lt;a href=&quot;https://www.linkedin.com/in/jonnyzzz/&quot;&gt;LinkedIn&lt;/a&gt; or
&lt;a href=&quot;https://twitter.com/jonnyzzz&quot;&gt;Twitter&lt;/a&gt; if you build something fun with AI voices.&lt;/p&gt;

&lt;p&gt;Stay tuned, I will prepare something similar with NVIDIA DGX Spart setup for some conferences in the furure!&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="ai" />
  
    <category term="tts" />
  
    <category term="python" />
  
    <category term="qwen" />
  
    <category term="voice-cloning" />
  
    <summary type="html">Building a Russian Loto announcer with 12 celebrity AI voices using Qwen3-TTS</summary>
  
  </entry>
  
  <entry>
    <title type="html">Orchestrating AI Fleets: When Agents Manage Agents</title>
    <link href="https://jonnyzzz.com/blog/2026/01/30/orchestrating-ai-fleets/" rel="alternate" type="text/html" title="Orchestrating AI Fleets: When Agents Manage Agents" />
    <published>2026-01-30T00:00:00+00:00</published>
    <updated>2026-01-30T00:00:00+00:00</updated>
    <id>/blog/2026/01/30/orchestrating-ai-fleets</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/01/30/orchestrating-ai-fleets/">&lt;p&gt;For the last several days, I have made my AI Agents call each other. Claude Code, Codex, and Gemini. 
After several agentic improvements, the root prompt does the following steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Instructs an agent to copy and adjust the prompt for their task&lt;/li&gt;
  &lt;li&gt;Instructs to use the standard &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run-agent.sh&lt;/code&gt; start agents, log outputs&lt;/li&gt;
  &lt;li&gt;Clearly states that the AI agent should use the script, not the embedded feature&lt;/li&gt;
  &lt;li&gt;Starts the agent at any working folder&lt;/li&gt;
  &lt;li&gt;One more secret ingredient to make it work, or two&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One AI Agent controls the flow of a fleet of other agents. It is much better than just a bash loop, 
and I like how it performs and adapts to the task given.&lt;/p&gt;

&lt;p&gt;Today:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Deep research on a product topic was conducted by 16+ agents&lt;/li&gt;
  &lt;li&gt;Code reading of a big monorepo, so the agent could understand how to implement the REST API client&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Claude Code calling multiple agents on the JetBrains Space reposiotry to mine knowledge from my repositories
&lt;img src=&quot;/images/posts/2026-01-30-orchestrating-ai-fleets-example.png&quot; alt=&quot;Claude Code orchestrating multiple agents&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is more&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Agent processes never ask me, and bother much less&lt;/li&gt;
  &lt;li&gt;I manage to make a root AI Agent run for hours unattended&lt;/li&gt;
  &lt;li&gt;It keeps the context small for each and avoid context rot&lt;/li&gt;
  &lt;li&gt;One can manage 3-5 such sessions, and I want to grow this number&lt;/li&gt;
  &lt;li&gt;The baseline is still the &lt;a href=&quot;https://jonnyzzz.com/RLM.md&quot;&gt;https://jonnyzzz.com/RLM.md&lt;/a&gt;,
which I based on the outcomes of my multiple experiments&lt;/li&gt;
  &lt;li&gt;Look what I’ve done &lt;a href=&quot;https://mcp-steroid.jonnyzzz.com&quot;&gt;MCP Steroid&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What’s next? One part say – do measurements. I will keep experimenting at the first place, 
and I need a partnership to set it up in a more scientific manner.&lt;/p&gt;

&lt;p&gt;This work builds directly on the success of my previous experiment 
where &lt;a href=&quot;/blog/2026/01/24/16-ai-agents-documentation-refactor/&quot;&gt;16 AI Agents Fixed Our Documentation Problem&lt;/a&gt;
and relies heavily on the &lt;a href=&quot;/blog/2026/01/05/rlm-multi-agent-orchestration/&quot;&gt;Recursive Language Model (RLM)&lt;/a&gt;
methodology I established earlier this year.&lt;/p&gt;

&lt;p&gt;The fleet is busy workin’
&lt;img src=&quot;/images/posts/2026-01-30-orchestrating-ai-fleets-busy-working.png&quot; alt=&quot;AI Agent fleet busy working&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Happy Friday!&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="ai-agents" />
  
    <category term="multi-agent" />
  
    <category term="orchestration" />
  
    <category term="automation" />
  
    <category term="llm" />
  
    <summary type="html">AI Agents call each other by themselves: One controls the flow, others work on the short task</summary>
  
  </entry>
  
  <entry>
    <title type="html">Coding in English with AI</title>
    <link href="https://jonnyzzz.com/blog/2026/01/27/coding-in-english-with-ai/" rel="alternate" type="text/html" title="Coding in English with AI" />
    <published>2026-01-27T00:00:00+00:00</published>
    <updated>2026-01-27T00:00:00+00:00</updated>
    <id>/blog/2026/01/27/coding-in-english-with-ai</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/01/27/coding-in-english-with-ai/">&lt;p&gt;About a year ago, I was wondering when programming would move to natural languages, and what it would look like.
&lt;strong&gt;Now I know&lt;/strong&gt;. For the last two months, English has become my main coding language to instruct AI agents,
build pipelines, and architect systems. &lt;strong&gt;I’m coding in English to make AI Agents code in code.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Running sub-agents is the new trend. We move from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ralph&lt;/code&gt; towards a multiple-agent swarm, 
where an agent calls sub-agents and monitors the outcomes.
ClaudeCode and Codex (and other vendors) recently included sub-agent support, too.
You make bigger tasks smaller by running sub-agents, and only if the whole chain of command can start sub-agents 
do we have the ability to split tasks, iterate, and so on.&lt;/p&gt;

&lt;p&gt;My main challenge is to check whether an agent can control sub-agents, 
so instead of a bash or Python loop, we put a managing agent at the top who will review 
the outcomes and decide on the next step.&lt;/p&gt;

&lt;p&gt;The whole agentic development process starts to look like an agentic waterflow workflow of many activities, each of which
is done my various AI agents, or even multiple agents, with multiple various 
agentic roles, repeats, and cycles. Should something go wrong, it should restart. 
I created a ~10-step instruction locally for a 25-year-old monorepo and keep testing it to see how
it goes. Agents tend to use the native sub-agent implementation instead of running the console 
script, so I need to explain more carefully that I need processes created. Running sub agent
as sub process gives the sub agent more power, another working directory, another &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CLAUDE.md/AGENTS.md&lt;/code&gt;,
different MCP Servers, and much more fresh context. And we can switch between different agents
within the same waterflow.&lt;/p&gt;

&lt;p&gt;After all iterations and tuning, it looks like Codex can do that better. Sometimes it falls back
to native sub-agent implementation. And my goal is to make agentic swarm function by itself
most of the time. Agents should cooperate to decide on the complex problems, research for solutions.&lt;/p&gt;

&lt;p&gt;Agents can fix your prompts, that is how I improved mine as well. Just ask it to start all 
supported agents to interview them for problems and suggestions. Process outcomes with agents.&lt;/p&gt;

&lt;p&gt;With that, I came to the next question: how can one monitor the graph of agents running? Not that I 
want to interact, just out of curiosity. Agents helped me create the monitoring scripts for 
that, so now I can see all agents started. Such code
is cheap, and experimentation is not blocked by that.&lt;/p&gt;

&lt;p&gt;Today, I have multiple code repositories of &lt;strong&gt;prompts&lt;/strong&gt;. I task selected agents to write prompts 
for their sub-agents. I version-control and back-up kilobytes of prompts. I ask agents
to interview agents on selected agentic integration topics. And of course some agents
will code, run tests in IntelliJ via the &lt;a href=&quot;https://mcp-steroid.jonnyzzz.com/&quot;&gt;MCP Steroid&lt;/a&gt;
plugin, debug the code and so on.&lt;/p&gt;

&lt;p&gt;We are approaching a shift where AI Agents become the primary users of software development tools.
The ‘Buying Persona’ remains human, but the ‘User Persona’ is becoming digital. Tools must
now be optimized for agentic consumption — APIs first, GUIs second.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;About a year ago, I was wondering when programming would move to natural languages, and what it would look like.
&lt;strong&gt;Now I know&lt;/strong&gt;. For the last two months, English has become my main coding language to instruct AI agents,
build pipelines, and architect systems. &lt;strong&gt;I’m coding in English to make AI Agents code in code.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I’m coding in English to make AI Agents code in code.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;instead-of-conclusion&quot;&gt;Instead of Conclusion&lt;/h2&gt;
&lt;p&gt;Below is what Gemini 3 told me&lt;/p&gt;

&lt;p&gt;The landscape of software development is undergoing a seismic shift. For decades, learning to code 
meant mastering syntax, understanding memory management, and debugging cryptic error messages. Today, 
with the rise of powerful AI models, the most important programming language might just be English.&lt;/p&gt;

&lt;h3 id=&quot;the-shift-from-syntax-to-semantics&quot;&gt;The Shift from Syntax to Semantics&lt;/h3&gt;

&lt;p&gt;Traditionally, developers acted as translators, converting human intent into machine-readable 
code. AI agents are now taking over this translation layer.&lt;/p&gt;

&lt;h3 id=&quot;prompt-engineering-as-the-new-coding&quot;&gt;Prompt Engineering as the New Coding&lt;/h3&gt;

&lt;p&gt;Writing clear, unambiguous instructions—prompt engineering—is becoming a critical skill. It 
shares many principles with traditional coding: precision, modularity, and iterative refinement.&lt;/p&gt;

&lt;h3 id=&quot;the-future-of-development&quot;&gt;The Future of Development&lt;/h3&gt;

&lt;p&gt;Does this mean the end of programmers? Unlikely. Instead, it elevates the role of the 
developer from a bricklayer to an architect. We spend less time on boilerplate and more 
time on system design and problem-solving.&lt;/p&gt;

&lt;h3 id=&quot;conclusion-by-ai&quot;&gt;Conclusion by AI&lt;/h3&gt;

&lt;p&gt;Coding in English doesn’t mean coding without thinking. It requires a different kind of discipline—one 
focused on clarity of thought and structural understanding.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;I’m coding in English to make AI Agents code in code.&lt;/strong&gt;&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="ai" />
  
    <category term="coding" />
  
    <category term="future" />
  
    <category term="ai-agents" />
  
    <category term="multi-agent" />
  
    <category term="sub-agent" />
  
    <summary type="html">Coding became natural language</summary>
  
  </entry>
  
  <entry>
    <title type="html">How 16 AI Agents Fixed Our Documentation Problem</title>
    <link href="https://jonnyzzz.com/blog/2026/01/24/16-ai-agents-documentation-refactor/" rel="alternate" type="text/html" title="How 16 AI Agents Fixed Our Documentation Problem" />
    <published>2026-01-24T00:00:00+00:00</published>
    <updated>2026-01-24T00:00:00+00:00</updated>
    <id>/blog/2026/01/24/16-ai-agents-documentation-refactor</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/01/24/16-ai-agents-documentation-refactor/">&lt;p&gt;I’ve been documenting multi-agent orchestration patterns for months, and I had no idea how bad our docs had become
until I asked our customers — AI agents, and they were brutally honest.&lt;/p&gt;

&lt;p&gt;Our documentation had grown to 2,648 lines across four files. The most important commands were buried at line 91 of
CLAUDE-CODE.md, after 90 lines of introductions, explanations, and edge cases. We’d duplicated entire sections across
three CLI docs. And when AI agents tried to use these docs to spawn other AI agents, they struggled.&lt;/p&gt;

&lt;p&gt;Here’s the recursive twist: I sent agents to interview agents about documentation for spawning agents. We used
multi-agent orchestration to fix documentation about multi-agent orchestration. The tools improved themselves.&lt;/p&gt;

&lt;p&gt;This is the story of how 16 AI agents helped us refactor documentation that was both about them and for them. This was
attempt #3, and we finally got it right by doing something simple: we stopped guessing and started asking.&lt;/p&gt;

&lt;h2 id=&quot;the-bigger-picture&quot;&gt;The Bigger Picture&lt;/h2&gt;

&lt;p&gt;This wasn’t just about fixing documentation. It was about proving something I’d suspected but couldn’t demonstrate:
multi-agent orchestration works for real engineering problems, not just toy examples.&lt;/p&gt;

&lt;p&gt;I’ve been experimenting with multi-agent patterns for months, documenting the RLM methodology, building orchestration
guides. But until this project, I hadn’t stress-tested it on something complex and messy. Documentation refactoring is
exactly that - subjective, iterative, full of judgment calls.&lt;/p&gt;

&lt;p&gt;Here’s where it gets meta-recursive: we used agents to spawn agents to interview agents about documentation that
teaches agents how to spawn agents. The documentation problem was its own solution. We needed better docs for
multi-agent orchestration, so we used multi-agent orchestration to improve those docs. The methodology ate its own
dogfood and came out stronger.&lt;/p&gt;

&lt;p&gt;The fact that 16 AI agents could analyze, interview, implement, and validate better than I could alone? That changes
how I think about engineering workflows. But more importantly, the agents-spawning-agents-to-fix-agent-docs approach
proved the recursive viability of the entire pattern.&lt;/p&gt;

&lt;p&gt;We spawned 16 agents across four distinct phases. We ran them in parallel when possible, sequentially when necessary.
We treated AI agents as actual customers and conducted structured interviews to understand their needs. We validated
the results with fresh agents who had no prior context. Some of those interview agents spawned their own sub-agents to
dig deeper into specific sections.&lt;/p&gt;

&lt;p&gt;The outcome? Measurable improvements: 39% shorter documentation, 15% higher quality ratings, 5x faster navigation to
key commands. Production-ready output that both humans and AI agents can use effectively.&lt;/p&gt;

&lt;p&gt;But the bigger lesson is about treating AI agents as customers. They can’t be polite out of social obligation. They
won’t pretend to understand confusing documentation. They’ll tell you exactly where you buried the lead, what’s
missing, and what’s duplicated. They’re brutally honest feedback machines. And when they give feedback about their own
operational instructions? That’s when the recursion gets really interesting.&lt;/p&gt;

&lt;h2 id=&quot;why-this-mattered&quot;&gt;Why This Mattered&lt;/h2&gt;

&lt;h3 id=&quot;the-dual-role-problem&quot;&gt;The Dual Role Problem&lt;/h3&gt;

&lt;p&gt;We’d written 2,648 lines of documentation across four files: CLAUDE-CODE.md, CODEX.md, GEMINI.md, and MULTI-AGENT.md. 
Standard developer docs, right? Not quite.&lt;/p&gt;

&lt;p&gt;The twist: this documentation was both &lt;strong&gt;about&lt;/strong&gt; AI agents and &lt;strong&gt;for&lt;/strong&gt; AI agents. Human developers would read it to 
learn how to spawn sub-agents. But more importantly, the AI agents themselves would read these docs when they needed to 
spawn other AI agents. An agent working on your behalf would need to parse these instructions, understand the patterns, 
and correctly invoke another agent with the right commands and flags.&lt;/p&gt;

&lt;p&gt;If the documentation was confusing, ambiguous, or poorly structured, the AI wouldn’t just get frustrated and ask for 
clarification. It would hallucinate. It would guess. It would burn the context and tokens to figure out the right
parameters. It would use the wrong flags or miss critical setup steps. The 
documentation quality directly impacted whether agent-to-agent orchestration actually worked.&lt;/p&gt;

&lt;h3 id=&quot;why-ai-agents-care-about-documentation-quality&quot;&gt;Why AI Agents Care About Documentation Quality&lt;/h3&gt;

&lt;p&gt;AI agents aren’t just slower readers than humans - they have fundamentally different constraints:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Token costs are real.&lt;/strong&gt; Reading 2,648 lines of documentation translates to roughly 40,000 tokens. Every time an agent 
needed to spawn a sub-agent, it would load these docs into context. That’s not just slow, it’s expensive. Token costs 
compound across every operation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Context limits matter.&lt;/strong&gt; Even with 200K token context windows, shorter is better. The more documentation an agent has 
to process, the slower it responds and the more likely it is to miss crucial details buried in the middle.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Precision matters more than style.&lt;/strong&gt; Ambiguity that humans can resolve through intuition becomes a hallucination risk 
for AI. When documentation says three commands are “RECOMMENDED” with no clear priority, humans might make an educated 
guess. AI agents will pick the first one they see, or worse, combine flags in creative ways that don’t work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Navigation is harder.&lt;/strong&gt; Humans can Ctrl+F for keywords or skim section headers. AI agents must parse the document 
sequentially, building a mental model as they go. If the most important information is at line 91, they’ve already 
spent 90 lines of processing budget on preliminaries.&lt;/p&gt;

&lt;h3 id=&quot;the-meta-challenge&quot;&gt;The Meta-Challenge&lt;/h3&gt;

&lt;p&gt;Here’s what made this interesting: we needed documentation good enough that an AI reading it could correctly spawn 
another AI, which might then need to spawn yet another AI. The clarity requirements weren’t just high - they were 
recursive. Every ambiguity would compound across agent hierarchies.&lt;/p&gt;

&lt;p&gt;One validator put it perfectly:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Strong operational doc. With recommended command moved to top and error handling added, would be 9/10.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That quote came from an AI agent evaluating the documentation. And it nailed exactly what was missing: quick access to 
the essential commands and proper error handling patterns.&lt;/p&gt;

&lt;p&gt;This was our third attempt. The first two? We tested on agents, and improved with agents with various prompts. 
Each next iteration creates a more improved outcome. But I would not run it too many times to avoid a drift
from the main focus. I’d optimized for completeness over usability, documenting every option and edge case
while forgetting to answer the only question that mattered: “What command do I run right now?”&lt;/p&gt;

&lt;p&gt;What changed? We stopped assuming we knew what good documentation looked like and started treating AI agents as actual 
customers who could tell us. They knew what they needed better than I did.&lt;/p&gt;

&lt;h2 id=&quot;what-the-interviews-revealed&quot;&gt;What the Interviews Revealed&lt;/h2&gt;

&lt;p&gt;The interview data surprised the root agent — seven agents, completely independent, and they all complained 
about the same five things. That kind of consistency doesn’t lie.&lt;/p&gt;

&lt;h3 id=&quot;pain-point-1-buried-the-lead&quot;&gt;Pain Point #1: Buried the Lead&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Severity: HIGH (reported by 5/7 interviews)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This was the killer. I’d buried our most important command at line 91 in CLAUDE-CODE.md, after 90 lines of 
introductions, prerequisites, and edge cases.&lt;/p&gt;

&lt;p&gt;From Interview #1:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Most important command (line 91) hidden after 90 lines of setup. Users want copy-paste immediately.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Looking back, I see exactly what went wrong. I wrote the docs the way I’d learned to write academic papers: 
introduction, background, methodology, results. But documentation isn’t a paper. Users want the answer immediately.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Before:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Introduction]
[Background]
[Architecture overview]
[Installation]
[Configuration]
[Prerequisites]
...
Line 91: # RECOMMENDED: Use this command...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;After:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Purpose
Command-line interface for spawning Claude Code sub-agents.

### Quick Start
# THIS IS THE ONE COMMAND YOU NEED
claude -p --tools default --permission-mode dontAsk &quot;prompt&quot; 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Impact:&lt;/strong&gt; Time-to-command dropped from 60-90 seconds to 10-15 seconds. For an AI agent reading sequentially, that’s a 
5x improvement. For a human developer scanning the page, it’s the difference between finding what you need and giving 
up.&lt;/p&gt;

&lt;h3 id=&quot;pain-point-2-error-handling-completely-absent&quot;&gt;Pain Point #2: Error Handling Completely Absent&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Severity: HIGH (4/7 interviews)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not a single retry example. No timeout recommendations. Zero guidance on detecting token limits or API errors. No exit 
code documentation. Our docs assumed success on first try, which is approximately never how real agent orchestration 
works.&lt;/p&gt;

&lt;p&gt;Agent feedback from Interview #4:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“No guidance on detecting token limits/API errors. No concrete retry example with exit code checking.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This wasn’t an edge case concern. Four separate agents independently identified it as a blocker. When your sub-agent 
hits a rate limit at 3 AM, you need to know: retry or fail? How long to wait? What exit code means “try again” vs “give 
up”?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The fix:&lt;/strong&gt; Added Part 9 to MULTI-AGENT.md with production-ready error handling patterns:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;MAX_RETRIES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3
&lt;span class=&quot;nv&quot;&gt;RETRY_COUNT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0
&lt;span class=&quot;nv&quot;&gt;TIMEOUT_SEC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;900

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$RETRY_COUNT&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-lt&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$MAX_RETRIES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
  if &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$TIMEOUT_SEC&lt;/span&gt; claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk &lt;span class=&quot;s2&quot;&gt;&quot;prompt&quot;&lt;/span&gt; 2&amp;gt;&amp;amp;1&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;SUCCESS&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;break
  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fi
  &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;EXIT_CODE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$?&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Attempt &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$((&lt;/span&gt;RETRY_COUNT+1&lt;span class=&quot;k&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$MAX_RETRIES&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; failed (exit &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$EXIT_CODE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)&quot;&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;RETRY_COUNT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$((&lt;/span&gt;RETRY_COUNT &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;sleep&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$((&lt;/span&gt;RETRY_COUNT &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Exponential backoff: 2s, 4s, 6s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The new section includes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Retry logic with exponential backoff (2s, 4s, 6s delays)&lt;/li&gt;
  &lt;li&gt;Timeout recommendations by task type (30s for simple queries, 600s for complex analysis)&lt;/li&gt;
  &lt;li&gt;Exit code meanings (0 = success, 1 = general error, 41 = rate limit, 124 = timeout)&lt;/li&gt;
  &lt;li&gt;Token limit detection patterns (grep for specific error messages)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pain-point-3-authentication-steps-missing&quot;&gt;Pain Point #3: Authentication Steps Missing&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Severity: HIGH (3/7 interviews)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;CODEX.md referenced &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.codex/auth.json&lt;/code&gt; in multiple places but never explained how to create it. I’d assumed you’d 
already authenticated before reading the docs.&lt;/p&gt;

&lt;p&gt;Interview #6 agent feedback:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Document never explains how auth.json is created. Assumes user already authenticated.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is the classic curse of knowledge. As the person who wrote the docs, I already had &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;auth.json&lt;/code&gt; on my machine. I’d 
logged in months ago. The auth step was invisible to me, but catastrophic for new users.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The fix:&lt;/strong&gt; Added Prerequisites sections to all three CLI docs with step-by-step auth flow:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Verify installation: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;codex --version&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Authenticate: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;codex login&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Confirm: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ls ~/.codex/auth.json&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Test: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;codex exec &quot;hello&quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Plus a troubleshooting table for common issues:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Symptom&lt;/th&gt;
      &lt;th&gt;Diagnosis&lt;/th&gt;
      &lt;th&gt;Fix&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;auth.json not found&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Not logged in yet&lt;/td&gt;
      &lt;td&gt;Run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;codex login&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;invalid credentials&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Token expired&lt;/td&gt;
      &lt;td&gt;Run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;codex login&lt;/code&gt; again&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;permission denied&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Wrong file permissions&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;chmod 600 ~/.codex/auth.json&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;pain-point-4-20-token-overhead-from-duplication&quot;&gt;Pain Point #4: 20% Token Overhead from Duplication&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Severity: HIGH (reported by 2/7 interviews, measured by our team)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We’d copy-pasted entire sections across CLAUDE-CODE.md, CODEX.md, and GEMINI.md:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MCP visibility tables (nearly identical, 80+ lines each)&lt;/li&gt;
  &lt;li&gt;Parallel execution patterns (minimal CLI differences, 100+ lines)&lt;/li&gt;
  &lt;li&gt;DO/DON’T best practices lists (word-for-word duplicates, 50+ lines)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This created 795 lines of duplicated content - content that every agent reading any CLI doc had to parse.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The fix:&lt;/strong&gt; Extract to MULTI-AGENT.md as single source of truth. CLI docs now reference rather than duplicate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Total lines: 2,648 → 1,618 (-39%)&lt;/li&gt;
  &lt;li&gt;Estimated tokens: ~40,000 → ~32,000 (-20%)&lt;/li&gt;
  &lt;li&gt;Maintenance burden: Update 1 file instead of 3&lt;/li&gt;
  &lt;li&gt;Consistency: No more drift between docs&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pain-point-5-mcp-troubleshooting-confusion&quot;&gt;Pain Point #5: MCP Troubleshooting Confusion&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Severity: MEDIUM (2/7 interviews)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Users didn’t understand when Model Context Protocol servers were available to sub-agents, or how to diagnose visibility 
issues. The docs mentioned MCP but never explained the inheritance rules or debugging steps.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The fix:&lt;/strong&gt; Added MCP Troubleshooting section with diagnostic table:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Symptom&lt;/th&gt;
      &lt;th&gt;Diagnosis&lt;/th&gt;
      &lt;th&gt;Fix&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Sub-agent doesn’t see MCP&lt;/td&gt;
      &lt;td&gt;Not registered globally&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;claude mcp add &amp;lt;name&amp;gt; &amp;lt;cmd&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MCP listed but unavailable&lt;/td&gt;
      &lt;td&gt;Restrictive tool flags&lt;/td&gt;
      &lt;td&gt;Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--tools default&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--tools none&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Connection errors&lt;/td&gt;
      &lt;td&gt;Server not running&lt;/td&gt;
      &lt;td&gt;Check IntelliJ IDE is open&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Works in parent, not in child&lt;/td&gt;
      &lt;td&gt;Command-line args block inheritance&lt;/td&gt;
      &lt;td&gt;Remove explicit &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--mcp&lt;/code&gt; flags&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Validation score:&lt;/strong&gt; One agent rated this 9/10, commenting: “diagnostic table format is perfect - covers the exact 
confusion I had.”&lt;/p&gt;

&lt;h3 id=&quot;the-one-command-problem&quot;&gt;The “ONE Command” Problem&lt;/h3&gt;

&lt;p&gt;This wasn’t in our original analysis, but three interviews independently mentioned it: CODEX.md had THREE commands 
marked “RECOMMENDED” with no clear priority.&lt;/p&gt;

&lt;p&gt;Agent feedback:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Ambiguity about which command to use. Mark ONE as primary for 95% of cases.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I thought I was being helpful by showing options. I was actually creating decision paralysis.&lt;/p&gt;

&lt;p&gt;The problem was real. We had:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# RECOMMENDED: Minimal non-interactive&lt;/span&gt;
codex &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;prompt&quot;&lt;/span&gt; 2&amp;gt;&amp;amp;1

&lt;span class=&quot;c&quot;&gt;# RECOMMENDED: Low-friction auto mode&lt;/span&gt;
codex &lt;span class=&quot;nt&quot;&gt;--full-auto&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;prompt&quot;&lt;/span&gt; 2&amp;gt;&amp;amp;1

&lt;span class=&quot;c&quot;&gt;# RECOMMENDED: Maximum tool access&lt;/span&gt;
codex &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;nt&quot;&gt;--full-auto&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;prompt&quot;&lt;/span&gt; 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Three “recommended” commands means zero recommended commands. An AI agent parsing this has to guess which one we 
actually want them to use.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The fix in CODEX.md:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;### Quick Start&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# ✅ THIS IS THE ONE COMMAND YOU NEED&lt;/span&gt;
codex &lt;span class=&quot;nt&quot;&gt;--full-auto&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;prompt&quot;&lt;/span&gt; 2&amp;gt;&amp;amp;1

Don&lt;span class=&quot;s1&quot;&gt;&apos;t use alternative flag combinations unless you have
a specific reason (debugging, restricting tool access, etc.)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Validation result:&lt;/strong&gt; 10/10 rating from independent reviewer: “Clear and effective. Zero ambiguity.”&lt;/p&gt;

&lt;p&gt;This became our guiding principle for all three CLI docs: users need ONE command to copy-paste. Not three options. Not 
a menu of flags. One command that works 95% of the time, with a separate “Advanced Usage” section for the 5% edge cases.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-implementation-rlm-in-action&quot;&gt;The Implementation: RLM in Action&lt;/h2&gt;

&lt;h3 id=&quot;what-is-rlm&quot;&gt;What Is RLM?&lt;/h3&gt;

&lt;p&gt;Before I explain how we fixed everything, let me introduce the pattern that made this possible.&lt;/p&gt;

&lt;p&gt;RLM, &lt;a href=&quot;https://arxiv.org/abs/2512.24601&quot;&gt;Recursive Language Model&lt;/a&gt;, is a workflow for breaking large 
tasks into parallel agent work. If you’ve used 
MapReduce for data processing, RLM is the same concept applied to AI agents:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PARTITION:&lt;/strong&gt; Divide work into independent tasks with clear boundaries. The rule: no inter-task dependencies. Each 
agent must be able to complete its work without waiting for another agent’s output. For this project, we partitioned by 
file: 5 agents, 5 files to refactor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MAP:&lt;/strong&gt; Execute all tasks simultaneously. Use shell background jobs (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;amp;&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wait&lt;/code&gt;) to run agents in parallel. Watch 
for rate limits - most APIs allow 3-5 concurrent requests. Each agent writes to its own output file to avoid conflicts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;REDUCE:&lt;/strong&gt; Manual synthesis of all outputs. This is where the human comes in. Check that cross-references align (no 
broken links between files). Verify terminology is consistent (don’t mix “sub-agent” and “child agent”). Ensure version 
numbers match. Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;diff&lt;/code&gt; to spot conflicts, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; to validate references, and manual review for quality.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;When RLM works:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tasks are independent (refactoring separate files)&lt;/li&gt;
  &lt;li&gt;Output format is structured (markdown, JSON)&lt;/li&gt;
  &lt;li&gt;Human can validate and merge results&lt;/li&gt;
  &lt;li&gt;Time savings justify coordination cost&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;When RLM fails:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tasks require sequential coordination (Agent 2 needs Agent 1’s output first)&lt;/li&gt;
  &lt;li&gt;Outputs conflict (both agents edit the same section differently)&lt;/li&gt;
  &lt;li&gt;API rate limits block parallelism entirely&lt;/li&gt;
  &lt;li&gt;Coordination overhead exceeds time savings&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this project: perfect RLM fit. Five files, five agents, independent work. Parallelism cut execution time from 2+ 
hours to 30 minutes for the implementation phase.&lt;/p&gt;

&lt;p&gt;Full methodology (chopped for agents by agents) with error handling patterns:
&lt;a href=&quot;https://jonnyzzz.com/RLM.md&quot;&gt;jonnyzzz.com/RLM.md&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;working-in-parallel&quot;&gt;Working in Parallel&lt;/h3&gt;

&lt;p&gt;Once we had customer feedback, I had a decision: fix these issues sequentially (safe, slow) or spawn parallel agents 
(risky, fast). I chose fast.&lt;/p&gt;

&lt;p&gt;We spawned 5 agents in parallel:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Agent 1: Refactor CLAUDE-CODE.md (Quick Start, error handling, auth setup)&lt;/li&gt;
  &lt;li&gt;Agent 2: Refactor CODEX.md (single “THE ONE command”, prerequisites, MCP troubleshooting)&lt;/li&gt;
  &lt;li&gt;Agent 3: Refactor GEMINI.md (consistency with other CLIs)&lt;/li&gt;
  &lt;li&gt;Agent 4: Add Part 9 to MULTI-AGENT.md (error handling patterns with retry logic)&lt;/li&gt;
  &lt;li&gt;Agent 5: Add Part 11 to MULTI-AGENT.md (cost management and token optimization)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This was the most nerve-wracking phase. Five agents working simultaneously meant five potential points of failure. If 
two agents edited the same section differently, we’d have merge conflicts. If one agent misunderstood the requirements, 
we’d ship broken docs. But the interviews were so specific - line numbers, severity ratings, concrete examples - that 
the risk felt manageable.&lt;/p&gt;

&lt;p&gt;Each agent received:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Specific pain points from interviews&lt;/li&gt;
  &lt;li&gt;Target file to modify&lt;/li&gt;
  &lt;li&gt;Success criteria (what “done” looks like)&lt;/li&gt;
  &lt;li&gt;Examples of desired patterns&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;timeline-and-reality-check&quot;&gt;Timeline and Reality Check&lt;/h3&gt;

&lt;p&gt;Here’s how the complete project actually played out:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase 1 - Discovery (30 minutes):&lt;/strong&gt;
4 analysis agents examined the existing documentation structure, identified duplication, and mapped pain points. 
Parallelism cut what would have been 2 hours of sequential reading down to 30 minutes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase 2 - Customer Interviews (45 minutes):&lt;/strong&gt;
9 interview agents spawned, though only 7 completed successfully (2 hit API rate limits). Most ran in parallel, with 
some sequential execution when we hit connection limits. This was the most valuable phase - getting honest feedback 
from agents who would actually use these docs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase 3 - Implementation (30 minutes execution, 2 hours human coordination):&lt;/strong&gt;
5 implementation agents working simultaneously on the actual file changes. Agent execution: 30 minutes. Human 
coordination in the reduce phase (checking cross-references, resolving version number mismatches, validating changes): 
2 hours. This is where the RLM pattern requires human oversight.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase 4 - Validation (30 minutes):&lt;/strong&gt;
3 fresh validator agents reviewed the updated documentation. No prior context, just “read this and tell us if it’s 
better.” I was genuinely nervous. What if the refactor made things worse? What if we’d optimized for the wrong thing?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Total: ~4 hours including human coordination, 2 hours of agent execution time&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Without parallelism? I’d still be refactoring. Twelve to fifteen hours of sequential work, minimum. Parallelism cut 
that to 4 hours total. That’s why this matters.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What went wrong:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;2 of 9 interview agents hit API rate limits and failed silently&lt;/li&gt;
  &lt;li&gt;Agent 4’s first attempt at error handling patterns was too generic - had to re-run with specific examples&lt;/li&gt;
  &lt;li&gt;Manual coordination in the Reduce phase took longer than expected because version numbers didn’t match across files&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;command-examples-how-to-interview-ai-agents&quot;&gt;Command Examples: How to Interview AI Agents&lt;/h3&gt;

&lt;p&gt;Here’s the actual command we used to spawn customer interview agents. These templates are copy-paste ready:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Template 1: Accessibility Audit&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;You are auditing CLAUDE-CODE.md for accessibility.

Answer these questions:
1. Where does the Quick Start section appear? (line number)
2. Can you find the most important command in 15 seconds? (yes/no + why)
3. What information is repeated unnecessarily? (quote sections)
4. Rate accessibility: 1-10

Max 300 words, be specific with line numbers.&quot;&lt;/span&gt; | &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk 2&amp;gt;&amp;amp;1 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; interview-accessibility.md
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Template 2: Completeness Check&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;You are checking CODEX.md for completeness.

Identify what&apos;s missing:
1. Prerequisites (installation, auth, dependencies)
2. Error handling (retry logic, timeouts, exit codes)
3. Examples (are they copy-paste ready?)
4. Rate completeness: 1-10

Max 300 words, cite line numbers.&quot;&lt;/span&gt; | &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk 2&amp;gt;&amp;amp;1 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; interview-completeness.md
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Template 3: Ambiguity Detection&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;You are identifying ambiguous documentation in GEMINI.md.

Find these issues:
1. Sections where the recommended action is unclear
2. Conflicting instructions (if any)
3. Jargon or undefined terms
4. Rate clarity: 1-10

Max 300 words, quote ambiguous phrases.&quot;&lt;/span&gt; | &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk 2&amp;gt;&amp;amp;1 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; interview-clarity.md
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The key flags:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-p&lt;/code&gt; (proactive mode): Let the agent use tools without asking&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--tools default&lt;/code&gt;: Give access to standard toolset (Read, Grep, etc.)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--permission-mode dontAsk&lt;/code&gt;: No interactive prompts, fully automated&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&amp;gt;&amp;amp;1&lt;/code&gt;: Capture both stdout and stderr&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For parallel execution, we used background jobs:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Run 3 interviews in parallel&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Interview 1 prompt&quot;&lt;/span&gt; | claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk 2&amp;gt;&amp;amp;1 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; interview-1.md&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;amp;

&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Interview 2 prompt&quot;&lt;/span&gt; | claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk 2&amp;gt;&amp;amp;1 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; interview-2.md&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;amp;

&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Interview 3 prompt&quot;&lt;/span&gt; | claude &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tools&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--permission-mode&lt;/span&gt; dontAsk 2&amp;gt;&amp;amp;1 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; interview-3.md&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;amp;

&lt;span class=&quot;nb&quot;&gt;wait
echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;All interviews complete&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wait&lt;/code&gt; command is critical - it ensures all background processes finish before proceeding to the next phase.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;validation-did-it-actually-work&quot;&gt;Validation: Did It Actually Work?&lt;/h2&gt;

&lt;h3 id=&quot;the-proof-version-108-testing&quot;&gt;The Proof: Version 1.0.8 Testing&lt;/h3&gt;

&lt;p&gt;After implementation, we had a problem: how do we know the refactored documentation is actually better? We couldn’t 
grade our own work. So we brought in external reviewers.&lt;/p&gt;

&lt;p&gt;Except our external reviewers were AI agents.&lt;/p&gt;

&lt;p&gt;We spawned 3 brand new agents with zero context. No memory of the interviews. No knowledge of what changed. Just: 
“Here’s the documentation. Evaluate it.”&lt;/p&gt;

&lt;p&gt;The first validator came back with an 8.5/10. I exhaled. The second: 9.0/10. I started to relax. The third validator’s 
report opened with: “This is exactly what I needed. Why didn’t it look like this before?”&lt;/p&gt;

&lt;p&gt;That question hit hard. Because I’d written the original docs. I’d thought they were good. I’d been wrong.&lt;/p&gt;

&lt;h3 id=&quot;beforeafter-scores&quot;&gt;Before/After Scores&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Document&lt;/th&gt;
      &lt;th&gt;v1.0.7 Score&lt;/th&gt;
      &lt;th&gt;v1.0.8 Score&lt;/th&gt;
      &lt;th&gt;Improvement&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CLAUDE-CODE.md&lt;/td&gt;
      &lt;td&gt;8.0/10&lt;/td&gt;
      &lt;td&gt;8.5/10&lt;/td&gt;
      &lt;td&gt;+6%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CODEX.md&lt;/td&gt;
      &lt;td&gt;7.0/10&lt;/td&gt;
      &lt;td&gt;9.0/10&lt;/td&gt;
      &lt;td&gt;+29%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MULTI-AGENT.md&lt;/td&gt;
      &lt;td&gt;8.0/10&lt;/td&gt;
      &lt;td&gt;9.0/10&lt;/td&gt;
      &lt;td&gt;+13%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;7.67/10&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;8.83/10&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;+15%&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The biggest improvement was CODEX.md - from 7.0 to 9.0. That makes sense: it had the most severe issues (3 
“recommended” commands, buried essentials, missing auth setup). The fixes were dramatic.&lt;/p&gt;

&lt;p&gt;CLAUDE-CODE.md saw a smaller gain because it was already the cleanest of the three. But even there, moving the Quick 
Start section to the top and adding error handling examples pushed it from “good” to “very good.”&lt;/p&gt;

&lt;h3 id=&quot;validator-quotes&quot;&gt;Validator Quotes&lt;/h3&gt;

&lt;p&gt;From VALIDATION-REPORT-v1.0.8.md:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Quick Start sections score 9-10/10 for accessibility”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The validators loved the new structure. Quick Start at the top meant they could find and execute the most important 
command in 15 seconds instead of scrolling through 90 lines of setup.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“‘THE ONE command’ messaging is clear and effective” (10/10)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CODEX.md went from 3 ambiguous “recommended” options to one crystal-clear primary command with explicit guidance on 
when to deviate. No more decision paralysis.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Diagnostic table format is perfect” (9/10)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The MCP troubleshooting table gave validators a quick reference for debugging. Symptom → Diagnosis → Fix. Exactly
what they needed.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Production-ready guidance with measurable metrics” (9/10)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Adding error handling patterns with concrete examples (retry logic, exit codes, timeouts) transformed the docs from 
“here’s what you can do” to “here’s how to do it reliably.”&lt;/p&gt;

&lt;h3 id=&quot;the-numbers&quot;&gt;The Numbers&lt;/h3&gt;

&lt;p&gt;Let’s look at the concrete efficiency metrics:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation efficiency:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Total lines: 2,648 → 1,618 (-39%)&lt;/li&gt;
  &lt;li&gt;Duplication: 795 lines repeated → 0 lines repeated&lt;/li&gt;
  &lt;li&gt;Distance to Quick Start: Line 90+ → Line 10-15 (80% closer)&lt;/li&gt;
  &lt;li&gt;Error handling patterns: 0 → 15+ examples added&lt;/li&gt;
  &lt;li&gt;Cost guidance: None → Comprehensive (Part 11 added)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Customer satisfaction:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Critical issues resolved: 5 out of 5 top pain points (100%)&lt;/li&gt;
  &lt;li&gt;Quality improvement: 7.67/10 → 8.83/10 (+15%)&lt;/li&gt;
  &lt;li&gt;Production ready: ✅ All 3 validators approved for production use&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Time savings:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Time to find recommended command: 60-90 seconds → 10-15 seconds (5x faster)&lt;/li&gt;
  &lt;li&gt;Time to understand error handling: ∞ (didn’t exist) → 2-3 minutes&lt;/li&gt;
  &lt;li&gt;Time to set up authentication: Failed often → Documented with Prerequisites section&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-surprise&quot;&gt;The Surprise&lt;/h3&gt;

&lt;p&gt;Here’s what I didn’t expect: the validators gave us higher scores (8.83/10) than the interviews did (7.67/10). Why?&lt;/p&gt;

&lt;p&gt;The interviewers were looking at broken documentation with a critical eye. The validators were looking at fixed 
documentation with no prior context. They didn’t know it had been worse. They just saw working, clear documentation and 
rated it highly.&lt;/p&gt;

&lt;p&gt;This taught us something about user research: users who experience the pain give you better feedback than users who 
only see the solution. The interview phase was more valuable than the validation phase, even though validation gave us 
better scores.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;what-i-learned&quot;&gt;What I Learned&lt;/h2&gt;

&lt;h3 id=&quot;interview-your-users-even-if-theyre-ais&quot;&gt;Interview Your Users (Even If They’re AIs)&lt;/h3&gt;

&lt;p&gt;I spent two full versions guessing what was wrong. Version 1.0.6? Not idea. Version 1.0.7? Still not good enough. 
One round of structured interviews revealed what users actually needed better than months of my assumptions.&lt;/p&gt;

&lt;p&gt;AI agents are surprisingly good at articulating what makes documentation effective. They can’t be polite out of social 
obligation — if it’s confusing, they’ll tell you.&lt;/p&gt;

&lt;p&gt;The practical takeaway: don’t assume, ask. Spawn 5-10 agents with structured questions, collect ratings, prioritize by 
frequency. That’s it.&lt;/p&gt;

&lt;h3 id=&quot;recommended-is-not-enough&quot;&gt;“Recommended” Is Not Enough&lt;/h3&gt;

&lt;p&gt;CODEX.md had three commands marked “RECOMMENDED” with no clear priority. As one validator put it: “Ambiguity about 
which command to use.” I thought I was being helpful by showing options. I was actually creating decision paralysis.&lt;/p&gt;

&lt;p&gt;Having three recommended commands equals having none. The fix: mark ONE primary command for 95% of use cases, then 
explain when to deviate. After this change, validators gave it a 10/10.&lt;/p&gt;

&lt;p&gt;Your users shouldn’t have to think about which tool to reach for.&lt;/p&gt;

&lt;h3 id=&quot;duplication-has-hidden-costs&quot;&gt;Duplication Has Hidden Costs&lt;/h3&gt;

&lt;p&gt;Twenty percent token overhead seems small until you multiply by every agent reading the docs, every spawned sub-agent, 
every validation test, and every future update requiring 3x maintenance work.&lt;/p&gt;

&lt;p&gt;We removed 795 lines of duplication, saving 8,000 tokens per agent spawn. The ROI calculation: 4 hours to remove 
duplication, 2x time saved per future update, break-even after 2-3 updates.&lt;/p&gt;

&lt;p&gt;Small percentages compound fast.&lt;/p&gt;

&lt;h3 id=&quot;error-handling-is-not-optional&quot;&gt;Error Handling Is Not Optional&lt;/h3&gt;

&lt;p&gt;Zero interviews complained about lack of advanced features. Four out of seven complained about missing error handling.&lt;/p&gt;

&lt;p&gt;Users need to know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;What to do when it fails (retry logic)&lt;/li&gt;
  &lt;li&gt;How long to wait (timeouts)&lt;/li&gt;
  &lt;li&gt;How to interpret errors (exit codes)&lt;/li&gt;
  &lt;li&gt;When to give up (max retries)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We added 15+ error handling patterns based on this feedback. The lesson: error states are not edge cases, they’re the 
primary use case for production systems.&lt;/p&gt;

&lt;h3 id=&quot;multi-agent-orchestration-works&quot;&gt;Multi-Agent Orchestration Works&lt;/h3&gt;

&lt;p&gt;Sixteen agents spawned across four phases - analysis, interviews, implementation, validation. What made it work:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Clear task boundaries&lt;/li&gt;
  &lt;li&gt;Independent work with no coordination needed within phases&lt;/li&gt;
  &lt;li&gt;Structured outputs in markdown&lt;/li&gt;
  &lt;li&gt;A reduce phase for synthesis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What didn’t work:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rate limits hit 2 of 9 interviews&lt;/li&gt;
  &lt;li&gt;Nested execution failed in practice&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The takeaway: plan for API constraints from the start, and test your assumptions about what’s actually possible before 
committing to a strategy.&lt;/p&gt;

&lt;h3 id=&quot;quantify-everything&quot;&gt;Quantify Everything&lt;/h3&gt;

&lt;p&gt;Without numbers, we would have “made it better” instead of 39% reduction, “users liked it” instead of 8.83/10 rating, 
and “faster to use” instead of 5x improvement.&lt;/p&gt;

&lt;p&gt;Metrics we tracked:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lines of code&lt;/li&gt;
  &lt;li&gt;Duplication percentage&lt;/li&gt;
  &lt;li&gt;Quality ratings&lt;/li&gt;
  &lt;li&gt;Time to key information&lt;/li&gt;
  &lt;li&gt;Issue resolution rate&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quantification turns vague improvements into compelling evidence. It also forces you to define what success looks like 
before you start.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;what-we-shipped&quot;&gt;What We Shipped&lt;/h2&gt;

&lt;p&gt;The refactor produced two types of deliverables: production files (what users actually read) and research artifacts 
(how we got there).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Production files (v1.0.8):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CLAUDE-CODE.md: 553 → 285 lines (-48%)&lt;/li&gt;
  &lt;li&gt;CODEX.md: 756 → 312 lines (-59%)&lt;/li&gt;
  &lt;li&gt;GEMINI.md: 757 → 327 lines (-57%)&lt;/li&gt;
  &lt;li&gt;MULTI-AGENT.md: 582 → 694 lines (+19%)&lt;/li&gt;
  &lt;li&gt;RLM.md (updated for consistency)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The numbers tell the story: three CLI docs lost more than half their length, while MULTI-AGENT.md grew slightly as the 
new single source of truth for shared patterns. Net result: 1,030 fewer lines to maintain, read, and pay tokens for.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Research artifacts (67.5 KB total):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ACTION-PLAN-v1.0.8.md (8.4 KB) - Implementation roadmap&lt;/li&gt;
  &lt;li&gt;FINAL-REPORT.md (12.1 KB) - Phase 1 summary&lt;/li&gt;
  &lt;li&gt;INTERVIEW-RESULTS.md (15.2 KB) - Customer feedback compilation&lt;/li&gt;
  &lt;li&gt;VALIDATION-REPORT-v1.0.8.md (8.7 KB) - Quality verification from fresh agents&lt;/li&gt;
  &lt;li&gt;RELEASE-NOTES-v1.0.8.md (9.2 KB) - Complete changelog with migration notes&lt;/li&gt;
  &lt;li&gt;REFACTOR-PLAN.md (6.3 KB) - Strategic analysis and approach&lt;/li&gt;
  &lt;li&gt;REFACTOR-SUMMARY.md (4.1 KB) - Before/after comparison with metrics&lt;/li&gt;
  &lt;li&gt;STATUS.md (3.5 KB) - Project status tracking&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These artifacts became their own form of documentation - showing not just what changed, but why, how, and whether it 
worked. Anyone can follow this pattern for their own documentation refactoring.&lt;/p&gt;

&lt;p&gt;All production files and research artifacts are available at &lt;a href=&quot;https://jonnyzzz.com/&quot;&gt;jonnyzzz.com&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lets-connect&quot;&gt;Let’s Connect&lt;/h2&gt;

&lt;p&gt;Share your results. Try this with your team’s documentation - I want to see your before/after metrics. Tag me on
&lt;a href=&quot;https://www.linkedin.com/in/jonnyzzz/&quot;&gt;LinkedIn at @jonnyzzz&lt;/a&gt; with your quality scores. Bonus points if your AI agents
are as brutally honest as mine were.&lt;/p&gt;

&lt;p&gt;Find a bug in the refactored docs? Submit PRs if you improve the patterns, let me know!&lt;/p&gt;

&lt;p&gt;And if you’re working on multi-agent orchestration or have questions about the RLM methodology, reach out. This is just
the beginning. We documented multi-agent orchestration, then used multi-agent orchestration to improve the
documentation about multi-agent orchestration. Agents spawning agents to interview agents. The recursive loop closed.&lt;/p&gt;

&lt;p&gt;Now go interview your AI customers. They’re waiting to tell you the truth.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next&lt;/h2&gt;

&lt;p&gt;The documentation is now production-ready. Quick Start sections appear in the first 15 lines. Error handling patterns
cover retry logic, timeouts, and exit codes. Authentication prerequisites are explicit. Duplication is eliminated. The
most common command is clearly marked as THE ONE command you need.&lt;/p&gt;

&lt;p&gt;But the research artifacts themselves became something more valuable: meta-documentation about improving documentation
through multi-agent orchestration. They show the complete workflow from analysis to interviews to validation to
deployment.&lt;/p&gt;

&lt;p&gt;The validation agents identified minor polish opportunities: reducing redundancy between Quick Start and Core Commands
sections, adding cost benchmark examples, making version requirements more specific. These are low-priority
improvements, not blockers, but they’re documented and ready for v1.0.9.&lt;/p&gt;

&lt;p&gt;I’m already thinking about the next iteration. Can we use this pattern for code refactoring? For test generation? For
architecture decisions? The interviews proved AI agents can articulate quality issues. The parallel implementation
proved they can fix those issues. That’s powerful.&lt;/p&gt;

&lt;p&gt;Next quarter, we’re applying this to actual codebase refactoring. The documentation was the proof of concept. The real
work is applying this to engineering workflows where the stakes are higher and the problems are messier. That’s where
this gets interesting.&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="ai-agents" />
  
    <category term="multi-agent" />
  
    <category term="sub-agent" />
  
    <category term="documentation" />
  
    <category term="rlm" />
  
    <summary type="html">We interviewed 7 AI agents about our documentation. After 16 agents and honest feedback - 39% shorter, 15% higher quality, 5x faster to use.</summary>
  
  </entry>
  
  <entry>
    <title type="html">Kotlin DSLs in 2026: Patterns That Stood the Test of Time</title>
    <link href="https://jonnyzzz.com/blog/2026/01/19/kotlin-dsl-2026/" rel="alternate" type="text/html" title="Kotlin DSLs in 2026: Patterns That Stood the Test of Time" />
    <published>2026-01-19T00:00:00+00:00</published>
    <updated>2026-01-19T00:00:00+00:00</updated>
    <id>/blog/2026/01/19/kotlin-dsl-2026</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/01/19/kotlin-dsl-2026/">&lt;p&gt;Eight years ago, I wrote about using Kotlin higher-order functions to simplify Java builders. 
Around the same time, I explored ad-hoc Gradle plugins and “The DSL Way”–replacing configuration 
files with type-safe Kotlin code. Looking back from 2026, these patterns have not only survived 
but have become fundamental to how we build modern JVM applications.&lt;/p&gt;

&lt;h2 id=&quot;the-core-idea-that-never-changed&quot;&gt;The Core Idea That Never Changed&lt;/h2&gt;

&lt;p&gt;The fundamental insight remains: Kotlin’s language features–extension functions, lambdas 
with receivers, and operator overloading–turn any API into a potential DSL.&lt;/p&gt;

&lt;p&gt;Consider the classic Java builder problem:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Traditional Java builder usage - verbose and error-prone&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JWT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withIssuer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ISSUER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withClaim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withClaim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;serviceId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serviceId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// Easy to copy-paste errors!&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;algorithm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The solution I proposed in 2018 still works perfectly:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withX&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JWT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withIssuer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ISSUER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withX&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;withClaim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;withX&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;serviceId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;withClaim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;serviceId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;algorithm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;what-has-evolved-scope-control&quot;&gt;What Has Evolved: Scope Control&lt;/h2&gt;

&lt;p&gt;Kotlin introduced &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@DslMarker&lt;/code&gt; for better scope control in DSLs:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@DslMarker&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;annotation&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConfigDsl&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;@ConfigDsl&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ServerConfig&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;lateinit&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DatabaseConfig&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DatabaseConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DatabaseConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ServerConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ServerConfig&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ServerConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@DslMarker&lt;/code&gt; annotation prevents accidentally calling outer scope functions from inner blocks.&lt;/p&gt;

&lt;h2 id=&quot;build-systems-gradle-kotlin-dsl-matured&quot;&gt;Build Systems: Gradle Kotlin DSL Matured&lt;/h2&gt;

&lt;p&gt;The patterns for ad-hoc plugins and code reuse have become standard:&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// buildSrc/src/main/kotlin/service-conventions.gradle.kts&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;plugins&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;kotlin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;jvm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;application&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;dependencies&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;implementation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;platform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.jetbrains.kotlin:kotlin-bom&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;implementation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;io.ktor:ktor-server-core:2.3.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The trick of using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$id:$id.gradle.plugin:$version&lt;/code&gt; to include plugin dependencies 
in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buildSrc&lt;/code&gt; remains the key insight for sharing complex build logic.&lt;/p&gt;

&lt;h2 id=&quot;configuration-as-code-the-dsl-way&quot;&gt;Configuration as Code: The DSL Way&lt;/h2&gt;

&lt;p&gt;The concept of transforming configuration files into executable Kotlin code has proven durable:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Parse the original format (properties, YAML, XML)&lt;/li&gt;
  &lt;li&gt;Generate readable Kotlin DSL code&lt;/li&gt;
  &lt;li&gt;Execute the DSL to produce the original format&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Instead of log4j.properties&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;log4j&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;console&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsoleAppender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;console&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PatternLayout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;conversionPattern&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;%d{ISO8601} [%t] %-5p %c - %m%n&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;rootLogger&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ERROR&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;appenders&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Variable references enable find-usages and rename refactoring. The type system catches invalid configurations at compile time.&lt;/p&gt;

&lt;h2 id=&quot;modern-use-cases&quot;&gt;Modern Use Cases&lt;/h2&gt;

&lt;p&gt;Beyond build systems, Kotlin DSLs have found homes in:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;API Client Generation&lt;/strong&gt;: Ktor uses DSLs for routing and request handling&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Infrastructure as Code&lt;/strong&gt;: Kotlin DSLs for Terraform or Pulumi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Pipelines&lt;/strong&gt;: Spark and Flink wrappers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UI Frameworks&lt;/strong&gt;: Compose is fundamentally a Kotlin DSL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-guidelines-for-dsl-design&quot;&gt;Practical Guidelines for DSL Design&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Start with the usage site&lt;/strong&gt;: Write how you want the DSL to look first&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@DslMarker&lt;/code&gt;&lt;/strong&gt;: Always add scope control&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prefer extension functions&lt;/strong&gt;: Keep core interfaces clean&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Make illegal states unrepresentable&lt;/strong&gt;: Use the type system&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Provide escape hatches&lt;/strong&gt;: Sometimes users need the underlying API&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Kotlin DSLs have moved from a clever technique to an essential tool in the JVM ecosystem. 
The patterns established years ago remain the foundation. What has changed is the tooling
maturity and breadth of applications.&lt;/p&gt;

&lt;p&gt;If you are still writing verbose Java builder code or maintaining error-prone configuration 
files, consider whether a thin Kotlin DSL layer could transform your development experience.&lt;/p&gt;

&lt;p&gt;The best programs remain immutable programs. And the best configurations are the ones that fail
at compile time, not in production.&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="kotlin" />
  
    <category term="java" />
  
    <category term="dsl" />
  
    <summary type="html">Eight years ago, I wrote about using Kotlin higher-order functions to simplify Java builders. Around the same time, I explored ad-hoc Gradle plugins and “The DSL Way”–replacing configuration files with type-safe Kotlin code. Looking back from 2026, these patterns have not only survived but have become fundamental to how we build modern JVM applications.</summary>
  
  </entry>
  
  <entry>
    <title type="html">Stop Optimizing Code Generation: Why Code Review Is Your Real SDLC Bottleneck</title>
    <link href="https://jonnyzzz.com/blog/2026/01/16/code-review-bottleneck/" rel="alternate" type="text/html" title="Stop Optimizing Code Generation: Why Code Review Is Your Real SDLC Bottleneck" />
    <published>2026-01-16T00:00:00+00:00</published>
    <updated>2026-01-16T00:00:00+00:00</updated>
    <id>/blog/2026/01/16/code-review-bottleneck</id>
    <content type="html" xml:base="https://jonnyzzz.com/blog/2026/01/16/code-review-bottleneck/">&lt;p&gt;Everyone is racing to make developers write code faster. GitHub Copilot promises 55% 
faster task completion. Cursor raised $2.3B on the promise of AI-native coding. Amazon 
launched Kiro. Google built Antigravity. The message is clear: AI will supercharge code generation.&lt;/p&gt;

&lt;p&gt;But here is the uncomfortable truth: &lt;strong&gt;coding was never your bottleneck.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-myth-of-the-coding-bottleneck&quot;&gt;The Myth of the Coding Bottleneck&lt;/h2&gt;

&lt;p&gt;According to IDC research, developers spend only 16% of their time actually 
writing code. Data from 250,000+ developers shows they code approximately 52 
minutes per day–about 4 hours and 21 minutes during a normal workweek.&lt;/p&gt;

&lt;p&gt;Where does the rest of the time go? Meetings, context switching, waiting for builds, 
debugging production issues, and–critically–&lt;strong&gt;waiting for code reviews&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;If your developers are only coding 16% of their day, making that 16% twice as fast 
means you have improved total developer throughput by… 8%. Meanwhile, the other 
84% of their time remains untouched.&lt;/p&gt;

&lt;h2 id=&quot;where-time-actually-goes-the-real-bottlenecks&quot;&gt;Where Time Actually Goes: The Real Bottlenecks&lt;/h2&gt;

&lt;p&gt;If you want to optimize your SDLC, you need to measure it. Here is what the data reveals:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Code Review Wait Times&lt;/strong&gt;
Elite development teams complete code reviews in under 3 hours, with 
pickup times under 75 minutes. Most teams are far from elite. When 
developers wait 3 days for a review, they context-switch to other 
work. Research shows it takes an average of 23 minutes to refocus after an interruption.&lt;/p&gt;

&lt;p&gt;At Meta, they found a direct correlation between slow code review times and engineer
dissatisfaction. When they optimized their review process, their average 
“Time In Review” dropped 7%, and diffs waiting longer than three days decreased by 12%.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Context Switching Costs&lt;/strong&gt;
Gerald Weinberg’s research demonstrates that adding a single extra 
project to a developer’s workload consumes 20% of their time through context 
switching. Add a third task, and half their time evaporates.&lt;/p&gt;

&lt;h2 id=&quot;why-code-review-is-the-right-place-for-ai&quot;&gt;Why Code Review Is the Right Place for AI&lt;/h2&gt;

&lt;p&gt;Code review sits at the intersection of several properties that make it ideal for AI assistance:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. High Volume, Repetitive Patterns&lt;/strong&gt;
Most code review feedback falls into predictable categories: style 
violations, null safety issues, missing error handling, deprecated
API usage, performance anti-patterns.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Expert Knowledge Is Scarce&lt;/strong&gt;
Every organization has “rock star” reviewers–the developers 
everyone wants reviewing their code. AI can extract patterns from these
experts’ historical reviews and apply them at scale.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Review Latency Compounds&lt;/strong&gt;
A 24-hour code review delay is not just 24 hours lost. It triggers context 
switching, creates WIP accumulation, and extends your entire change lead time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Human Reviewers Should Focus on Architecture, Not Syntax&lt;/strong&gt;
Senior developers’ time is better spent on architectural decisions, 
mentoring, and strategic code concerns–not catching missing null checks.&lt;/p&gt;

&lt;h2 id=&quot;action-items-for-engineering-leaders&quot;&gt;Action Items for Engineering Leaders&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Measure your SDLC&lt;/strong&gt; - Track where time actually goes. What is your median PR pickup time?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Identify your review bottlenecks&lt;/strong&gt; - Who are your rock star reviewers?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Start with automation of the mechanical&lt;/strong&gt; - Ensure CI and static analysis gates are in place before human review&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Extract patterns from your best reviewers&lt;/strong&gt; - Analyze historical review comments&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Measure the impact&lt;/strong&gt; - Track review cycle time before and after AI assistance&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;the-future&quot;&gt;The Future&lt;/h2&gt;

&lt;p&gt;I do believe that we are at the verge of automatic processes, you cannot
effectively benefit from AI tools if you keep doing 100% of some work manually
within your SDLC pipeline.&lt;/p&gt;

&lt;p&gt;We need to build automated code reviews, which will make our developers faster,
and which will allow us to process more code, partially automatically.&lt;/p&gt;

&lt;p&gt;In the long run, I believe, we are going to start building trust, and make AI a
natural pall and helper in the review process. Build it to make it to complete
5% of the reviews to make it trustworthy partner. And grow from that.&lt;/p&gt;

&lt;h2 id=&quot;the-future-reviewer&quot;&gt;The Future Reviewer&lt;/h2&gt;

&lt;p&gt;Given we have automated code reviews, where an AI agents can comment on the review,
they can propose suggested improvements, and humans for help.&lt;/p&gt;

&lt;p&gt;Such AI Agents need to learn from your existing code reviews, so you build skill and
principles, which your team is operating on. That is the way the trust is established.&lt;/p&gt;

&lt;p&gt;The learned principles should sit in the Markdown files directly in your repositories,
team should read, discuss, and update it.&lt;/p&gt;

&lt;p&gt;** Move all your water cooler conversations to the Markdown files, wikis, so agents can read that **&lt;/p&gt;

&lt;p&gt;Remote teams, that’s for you too!&lt;/p&gt;

&lt;h2 id=&quot;the-future-agentic-swarm&quot;&gt;The Future Agentic Swarm&lt;/h2&gt;

&lt;p&gt;Agents will be talking to each other. Like a coding agent will interact with the reviewers agents.&lt;/p&gt;

&lt;p&gt;As it works for humans today. No changes.&lt;/p&gt;

&lt;p&gt;And agents love working in the feedback loop, gamification!&lt;/p&gt;

&lt;h2 id=&quot;the-bigger-picture&quot;&gt;The Bigger Picture&lt;/h2&gt;

&lt;p&gt;The organizations that win will not be those who generate code fastest. They will be the 
ones who deliver value fastest – and that requires optimizing the entire software 
development lifecycle, not just the coding phase.&lt;/p&gt;

&lt;p&gt;Coding is not your bottleneck. It probably never was. The data is clear. Now it is time to put
AI where it will actually make a difference.&lt;/p&gt;

&lt;p&gt;Code review is waiting.&lt;/p&gt;</content>

  
  
  
  
  

    <author>
      <name>Eugene Petrenko</name>
    </author>

  
    <category term="ai" />
  
    <category term="developer-productivity" />
  
    <summary type="html">Everyone is racing to make developers write code faster. GitHub Copilot promises 55% faster task completion. Cursor raised $2.3B on the promise of AI-native coding. Amazon launched Kiro. Google built Antigravity. The message is clear: AI will supercharge code generation.</summary>
  
  </entry>
  
</feed>
